{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependency\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import psycopg2\n",
    "# import config as creds\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def connect():\n",
    "    \n",
    "#     # Set up a connection to the postgres server.\n",
    "#     conn_string = \"host=\"+ creds.PGHOST +\" port=\"+ \"5432\" +\" dbname=\"+ creds.PGDATABASE +\" user=\" + creds.PGUSER \\\n",
    "#                  +\" password=\"+ creds.PGPASSWORD\n",
    "    \n",
    "#     conn = psycopg2.connect(conn_string)\n",
    "#     #print(\"Connected!\")\n",
    "\n",
    "#     #Create a cursor object\n",
    "#     cursor = conn.cursor()\n",
    "    \n",
    "#     return conn, cursor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connecting to DB\n",
    "\n",
    "# conn, cursor = connect()\n",
    "\n",
    "# # SQL command to create inventory table\n",
    "# sql = \"select * from ames;\"\n",
    "# #cursor.execute(sql)\n",
    "# df = pd.read_sql_query(sql, conn)\n",
    "# #conn.commit()\n",
    "# # dat = pd.read_sql_query(sql, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ames_order</th>\n",
       "      <th>pid</th>\n",
       "      <th>mssubclass</th>\n",
       "      <th>lotarea</th>\n",
       "      <th>overallqual</th>\n",
       "      <th>overallcond</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>yearremodadd</th>\n",
       "      <th>masvnrarea</th>\n",
       "      <th>bsmtfinsf1</th>\n",
       "      <th>...</th>\n",
       "      <th>openporchsf</th>\n",
       "      <th>enclosedporch</th>\n",
       "      <th>3ssnporch</th>\n",
       "      <th>screenporch</th>\n",
       "      <th>poolarea</th>\n",
       "      <th>miscval</th>\n",
       "      <th>mosold</th>\n",
       "      <th>yrsold</th>\n",
       "      <th>saleprice</th>\n",
       "      <th>total_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2.762000e+03</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "      <td>2762.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1475.807024</td>\n",
       "      <td>7.216112e+08</td>\n",
       "      <td>55.787473</td>\n",
       "      <td>10315.285301</td>\n",
       "      <td>6.061188</td>\n",
       "      <td>5.598841</td>\n",
       "      <td>1970.230992</td>\n",
       "      <td>1983.510500</td>\n",
       "      <td>101.051050</td>\n",
       "      <td>449.106445</td>\n",
       "      <td>...</td>\n",
       "      <td>44.525344</td>\n",
       "      <td>23.640478</td>\n",
       "      <td>2.637944</td>\n",
       "      <td>16.598479</td>\n",
       "      <td>2.379797</td>\n",
       "      <td>53.492759</td>\n",
       "      <td>6.208545</td>\n",
       "      <td>2007.780956</td>\n",
       "      <td>179957.700579</td>\n",
       "      <td>4518.347936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>845.311212</td>\n",
       "      <td>1.887398e+08</td>\n",
       "      <td>41.149335</td>\n",
       "      <td>7974.263233</td>\n",
       "      <td>1.388714</td>\n",
       "      <td>1.118077</td>\n",
       "      <td>29.747730</td>\n",
       "      <td>20.733386</td>\n",
       "      <td>175.237801</td>\n",
       "      <td>457.444876</td>\n",
       "      <td>...</td>\n",
       "      <td>64.761717</td>\n",
       "      <td>65.157336</td>\n",
       "      <td>25.492483</td>\n",
       "      <td>57.200188</td>\n",
       "      <td>36.659759</td>\n",
       "      <td>583.100461</td>\n",
       "      <td>2.705908</td>\n",
       "      <td>1.315563</td>\n",
       "      <td>80219.266739</td>\n",
       "      <td>1413.430764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.263011e+08</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>668.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>751.250000</td>\n",
       "      <td>5.284390e+08</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7590.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1953.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129000.000000</td>\n",
       "      <td>3508.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1475.500000</td>\n",
       "      <td>9.021036e+08</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>9574.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1971.500000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>159000.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2206.750000</td>\n",
       "      <td>9.071940e+08</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>11668.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>738.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>211375.000000</td>\n",
       "      <td>5295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2930.000000</td>\n",
       "      <td>9.241520e+08</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1378.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "      <td>18812.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ames_order           pid   mssubclass        lotarea  overallqual  \\\n",
       "count  2762.000000  2.762000e+03  2762.000000    2762.000000  2762.000000   \n",
       "mean   1475.807024  7.216112e+08    55.787473   10315.285301     6.061188   \n",
       "std     845.311212  1.887398e+08    41.149335    7974.263233     1.388714   \n",
       "min       1.000000  5.263011e+08    20.000000    1300.000000     1.000000   \n",
       "25%     751.250000  5.284390e+08    20.000000    7590.000000     5.000000   \n",
       "50%    1475.500000  9.021036e+08    50.000000    9574.000000     6.000000   \n",
       "75%    2206.750000  9.071940e+08    70.000000   11668.500000     7.000000   \n",
       "max    2930.000000  9.241520e+08   190.000000  215245.000000    10.000000   \n",
       "\n",
       "       overallcond    yearbuilt  yearremodadd   masvnrarea   bsmtfinsf1  ...  \\\n",
       "count  2762.000000  2762.000000   2762.000000  2762.000000  2762.000000  ...   \n",
       "mean      5.598841  1970.230992   1983.510500   101.051050   449.106445  ...   \n",
       "std       1.118077    29.747730     20.733386   175.237801   457.444876  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1953.000000   1965.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1971.500000   1991.000000     0.000000   375.000000  ...   \n",
       "75%       6.000000  1999.000000   2003.000000   164.000000   738.750000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1378.000000  5644.000000  ...   \n",
       "\n",
       "       openporchsf  enclosedporch    3ssnporch  screenporch     poolarea  \\\n",
       "count  2762.000000    2762.000000  2762.000000  2762.000000  2762.000000   \n",
       "mean     44.525344      23.640478     2.637944    16.598479     2.379797   \n",
       "std      64.761717      65.157336    25.492483    57.200188    36.659759   \n",
       "min       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "50%      24.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "75%      66.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "max     742.000000    1012.000000   508.000000   576.000000   800.000000   \n",
       "\n",
       "            miscval       mosold       yrsold      saleprice    total_area  \n",
       "count   2762.000000  2762.000000  2762.000000    2762.000000   2762.000000  \n",
       "mean      53.492759     6.208545  2007.780956  179957.700579   4518.347936  \n",
       "std      583.100461     2.705908     1.315563   80219.266739   1413.430764  \n",
       "min        0.000000     1.000000  2006.000000   12789.000000    668.000000  \n",
       "25%        0.000000     4.000000  2007.000000  129000.000000   3508.500000  \n",
       "50%        0.000000     6.000000  2008.000000  159000.000000   4331.000000  \n",
       "75%        0.000000     8.000000  2009.000000  211375.000000   5295.000000  \n",
       "max    17000.000000    12.000000  2010.000000  755000.000000  18812.000000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Resources/cleaned_ames_dataset.csv')\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Data Cleaning before importing the dataset into our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>mssubclass</th>\n",
       "      <th>mszoning</th>\n",
       "      <th>lotarea</th>\n",
       "      <th>street</th>\n",
       "      <th>lotshape</th>\n",
       "      <th>landcontour</th>\n",
       "      <th>lotconfig</th>\n",
       "      <th>landslope</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>3ssnporch</th>\n",
       "      <th>screenporch</th>\n",
       "      <th>poolarea</th>\n",
       "      <th>miscval</th>\n",
       "      <th>mosold</th>\n",
       "      <th>yrsold</th>\n",
       "      <th>saletype</th>\n",
       "      <th>salecondition</th>\n",
       "      <th>saleprice</th>\n",
       "      <th>total_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "      <td>4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "      <td>3404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "      <td>4299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "      <td>6852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "      <td>4668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>923275080</td>\n",
       "      <td>80</td>\n",
       "      <td>RL</td>\n",
       "      <td>7937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142500</td>\n",
       "      <td>3597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>923276100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>8885</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Low</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Mod</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>131000</td>\n",
       "      <td>3152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>923400125</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132000</td>\n",
       "      <td>2852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>924100070</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>10010</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Mod</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>170000</td>\n",
       "      <td>4585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>924151050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Mod</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>188000</td>\n",
       "      <td>5646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2762 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pid  mssubclass mszoning  lotarea street lotshape landcontour  \\\n",
       "0     526301100          20       RL    31770   Pave      IR1         Lvl   \n",
       "1     526350040          20       RH    11622   Pave      Reg         Lvl   \n",
       "2     526351010          20       RL    14267   Pave      IR1         Lvl   \n",
       "3     526353030          20       RL    11160   Pave      Reg         Lvl   \n",
       "4     527105010          60       RL    13830   Pave      IR1         Lvl   \n",
       "...         ...         ...      ...      ...    ...      ...         ...   \n",
       "2757  923275080          80       RL     7937   Pave      IR1         Lvl   \n",
       "2758  923276100          20       RL     8885   Pave      IR1         Low   \n",
       "2759  923400125          85       RL    10441   Pave      Reg         Lvl   \n",
       "2760  924100070          20       RL    10010   Pave      Reg         Lvl   \n",
       "2761  924151050          60       RL     9627   Pave      Reg         Lvl   \n",
       "\n",
       "     lotconfig landslope neighborhood  ... 3ssnporch screenporch poolarea  \\\n",
       "0       Corner       Gtl        NAmes  ...         0           0        0   \n",
       "1       Inside       Gtl        NAmes  ...         0         120        0   \n",
       "2       Corner       Gtl        NAmes  ...         0           0        0   \n",
       "3       Corner       Gtl        NAmes  ...         0           0        0   \n",
       "4       Inside       Gtl      Gilbert  ...         0           0        0   \n",
       "...        ...       ...          ...  ...       ...         ...      ...   \n",
       "2757   CulDSac       Gtl      Mitchel  ...         0           0        0   \n",
       "2758    Inside       Mod      Mitchel  ...         0           0        0   \n",
       "2759    Inside       Gtl      Mitchel  ...         0           0        0   \n",
       "2760    Inside       Mod      Mitchel  ...         0           0        0   \n",
       "2761    Inside       Mod      Mitchel  ...         0           0        0   \n",
       "\n",
       "     miscval  mosold  yrsold  saletype  salecondition saleprice total_area  \n",
       "0          0       5    2010       WD          Normal    215000       4920  \n",
       "1          0       6    2010       WD          Normal    105000       3404  \n",
       "2      12500       6    2010       WD          Normal    172000       4299  \n",
       "3          0       4    2010       WD          Normal    244000       6852  \n",
       "4          0       3    2010       WD          Normal    189900       4668  \n",
       "...      ...     ...     ...       ...            ...       ...        ...  \n",
       "2757       0       3    2006       WD          Normal    142500       3597  \n",
       "2758       0       6    2006       WD          Normal    131000       3152  \n",
       "2759     700       7    2006       WD          Normal    132000       2852  \n",
       "2760       0       4    2006       WD          Normal    170000       4585  \n",
       "2761       0      11    2006       WD          Normal    188000       5646  \n",
       "\n",
       "[2762 rows x 66 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the ames_order, pid column since it doesn't help with prediction\n",
    "df.drop(columns=[\"ames_order\"], axis=1, inplace=True)\n",
    "# df.set_index(df['pid'],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pid              0\n",
       "mssubclass       0\n",
       "mszoning         0\n",
       "lotarea          0\n",
       "street           0\n",
       "                ..\n",
       "yrsold           0\n",
       "saletype         0\n",
       "salecondition    0\n",
       "saleprice        0\n",
       "total_area       0\n",
       "Length: 66, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping any NA before putting the dataset into our model\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Label Encoder to to transform categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pid               int64\n",
       "mssubclass       object\n",
       "mszoning         object\n",
       "lotarea           int64\n",
       "street           object\n",
       "                  ...  \n",
       "yrsold            int64\n",
       "saletype         object\n",
       "salecondition    object\n",
       "saleprice         int64\n",
       "total_area        int64\n",
       "Length: 66, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert numerical categories that shouldn't be numerical to categorical categories\n",
    "#please refer to the description file for definition of each category\n",
    "df['mssubclass'] = df['mssubclass'].astype(str)\n",
    "df['overallcond'] = df['overallcond'].astype(str)\n",
    "df['overallqual'] = df['overallqual'].astype(str)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names = <bound method Series.unique of 0       20\n",
      "1       20\n",
      "2       20\n",
      "3       20\n",
      "4       60\n",
      "        ..\n",
      "2757    80\n",
      "2758    20\n",
      "2759    85\n",
      "2760    20\n",
      "2761    60\n",
      "Name: mssubclass, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       RL\n",
      "1       RH\n",
      "2       RL\n",
      "3       RL\n",
      "4       RL\n",
      "        ..\n",
      "2757    RL\n",
      "2758    RL\n",
      "2759    RL\n",
      "2760    RL\n",
      "2761    RL\n",
      "Name: mszoning, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       Pave\n",
      "1       Pave\n",
      "2       Pave\n",
      "3       Pave\n",
      "4       Pave\n",
      "        ... \n",
      "2757    Pave\n",
      "2758    Pave\n",
      "2759    Pave\n",
      "2760    Pave\n",
      "2761    Pave\n",
      "Name: street, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       IR1\n",
      "1       Reg\n",
      "2       IR1\n",
      "3       Reg\n",
      "4       IR1\n",
      "       ... \n",
      "2757    IR1\n",
      "2758    IR1\n",
      "2759    Reg\n",
      "2760    Reg\n",
      "2761    Reg\n",
      "Name: lotshape, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       Lvl\n",
      "1       Lvl\n",
      "2       Lvl\n",
      "3       Lvl\n",
      "4       Lvl\n",
      "       ... \n",
      "2757    Lvl\n",
      "2758    Low\n",
      "2759    Lvl\n",
      "2760    Lvl\n",
      "2761    Lvl\n",
      "Name: landcontour, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0        Corner\n",
      "1        Inside\n",
      "2        Corner\n",
      "3        Corner\n",
      "4        Inside\n",
      "         ...   \n",
      "2757    CulDSac\n",
      "2758     Inside\n",
      "2759     Inside\n",
      "2760     Inside\n",
      "2761     Inside\n",
      "Name: lotconfig, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       Gtl\n",
      "1       Gtl\n",
      "2       Gtl\n",
      "3       Gtl\n",
      "4       Gtl\n",
      "       ... \n",
      "2757    Gtl\n",
      "2758    Mod\n",
      "2759    Gtl\n",
      "2760    Mod\n",
      "2761    Mod\n",
      "Name: landslope, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0         NAmes\n",
      "1         NAmes\n",
      "2         NAmes\n",
      "3         NAmes\n",
      "4       Gilbert\n",
      "         ...   \n",
      "2757    Mitchel\n",
      "2758    Mitchel\n",
      "2759    Mitchel\n",
      "2760    Mitchel\n",
      "2761    Mitchel\n",
      "Name: neighborhood, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0        Norm\n",
      "1       Feedr\n",
      "2        Norm\n",
      "3        Norm\n",
      "4        Norm\n",
      "        ...  \n",
      "2757     Norm\n",
      "2758     Norm\n",
      "2759     Norm\n",
      "2760     Norm\n",
      "2761     Norm\n",
      "Name: condition1, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       Norm\n",
      "1       Norm\n",
      "2       Norm\n",
      "3       Norm\n",
      "4       Norm\n",
      "        ... \n",
      "2757    Norm\n",
      "2758    Norm\n",
      "2759    Norm\n",
      "2760    Norm\n",
      "2761    Norm\n",
      "Name: condition2, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       1Fam\n",
      "1       1Fam\n",
      "2       1Fam\n",
      "3       1Fam\n",
      "4       1Fam\n",
      "        ... \n",
      "2757    1Fam\n",
      "2758    1Fam\n",
      "2759    1Fam\n",
      "2760    1Fam\n",
      "2761    1Fam\n",
      "Name: bldgtype, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       1Story\n",
      "1       1Story\n",
      "2       1Story\n",
      "3       1Story\n",
      "4       2Story\n",
      "         ...  \n",
      "2757      SLvl\n",
      "2758    1Story\n",
      "2759    SFoyer\n",
      "2760    1Story\n",
      "2761    2Story\n",
      "Name: housestyle, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0         Hip\n",
      "1       Gable\n",
      "2         Hip\n",
      "3         Hip\n",
      "4       Gable\n",
      "        ...  \n",
      "2757    Gable\n",
      "2758    Gable\n",
      "2759    Gable\n",
      "2760    Gable\n",
      "2761    Gable\n",
      "Name: roofstyle, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       Normal\n",
      "1       Normal\n",
      "2       Normal\n",
      "3       Normal\n",
      "4       Normal\n",
      "         ...  \n",
      "2757    Normal\n",
      "2758    Normal\n",
      "2759    Normal\n",
      "2760    Normal\n",
      "2761    Normal\n",
      "Name: salecondition, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       CompShg\n",
      "1       CompShg\n",
      "2       CompShg\n",
      "3       CompShg\n",
      "4       CompShg\n",
      "         ...   \n",
      "2757    CompShg\n",
      "2758    CompShg\n",
      "2759    CompShg\n",
      "2760    CompShg\n",
      "2761    CompShg\n",
      "Name: roofmatl, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       BrkFace\n",
      "1       VinylSd\n",
      "2       Wd Sdng\n",
      "3       BrkFace\n",
      "4       VinylSd\n",
      "         ...   \n",
      "2757    HdBoard\n",
      "2758    HdBoard\n",
      "2759    HdBoard\n",
      "2760    HdBoard\n",
      "2761    HdBoard\n",
      "Name: exterior1st, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       Plywood\n",
      "1       VinylSd\n",
      "2       Wd Sdng\n",
      "3       BrkFace\n",
      "4       VinylSd\n",
      "         ...   \n",
      "2757    HdBoard\n",
      "2758    HdBoard\n",
      "2759    Wd Shng\n",
      "2760    HdBoard\n",
      "2761    HdBoard\n",
      "Name: exterior2nd, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0         Stone\n",
      "1          None\n",
      "2       BrkFace\n",
      "3          None\n",
      "4          None\n",
      "         ...   \n",
      "2757       None\n",
      "2758       None\n",
      "2759       None\n",
      "2760       None\n",
      "2761    BrkFace\n",
      "Name: masvnrtype, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       TA\n",
      "1       TA\n",
      "2       TA\n",
      "3       Gd\n",
      "4       TA\n",
      "        ..\n",
      "2757    TA\n",
      "2758    TA\n",
      "2759    TA\n",
      "2760    TA\n",
      "2761    TA\n",
      "Name: exterqual, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       TA\n",
      "1       TA\n",
      "2       TA\n",
      "3       TA\n",
      "4       TA\n",
      "        ..\n",
      "2757    TA\n",
      "2758    TA\n",
      "2759    TA\n",
      "2760    TA\n",
      "2761    TA\n",
      "Name: extercond, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       CBlock\n",
      "1       CBlock\n",
      "2       CBlock\n",
      "3       CBlock\n",
      "4        PConc\n",
      "         ...  \n",
      "2757    CBlock\n",
      "2758    CBlock\n",
      "2759     PConc\n",
      "2760    CBlock\n",
      "2761     PConc\n",
      "Name: foundation, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       GasA\n",
      "1       GasA\n",
      "2       GasA\n",
      "3       GasA\n",
      "4       GasA\n",
      "        ... \n",
      "2757    GasA\n",
      "2758    GasA\n",
      "2759    GasA\n",
      "2760    GasA\n",
      "2761    GasA\n",
      "Name: heating, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       Fa\n",
      "1       TA\n",
      "2       TA\n",
      "3       Ex\n",
      "4       Gd\n",
      "        ..\n",
      "2757    TA\n",
      "2758    TA\n",
      "2759    TA\n",
      "2760    Gd\n",
      "2761    Ex\n",
      "Name: heatingqc, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       Y\n",
      "1       Y\n",
      "2       Y\n",
      "3       Y\n",
      "4       Y\n",
      "       ..\n",
      "2757    Y\n",
      "2758    Y\n",
      "2759    Y\n",
      "2760    Y\n",
      "2761    Y\n",
      "Name: centralair, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       SBrkr\n",
      "1       SBrkr\n",
      "2       SBrkr\n",
      "3       SBrkr\n",
      "4       SBrkr\n",
      "        ...  \n",
      "2757    SBrkr\n",
      "2758    SBrkr\n",
      "2759    SBrkr\n",
      "2760    SBrkr\n",
      "2761    SBrkr\n",
      "Name: electrical, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       TA\n",
      "1       TA\n",
      "2       Gd\n",
      "3       Ex\n",
      "4       TA\n",
      "        ..\n",
      "2757    TA\n",
      "2758    TA\n",
      "2759    TA\n",
      "2760    TA\n",
      "2761    TA\n",
      "Name: kitchenqual, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       Typ\n",
      "1       Typ\n",
      "2       Typ\n",
      "3       Typ\n",
      "4       Typ\n",
      "       ... \n",
      "2757    Typ\n",
      "2758    Typ\n",
      "2759    Typ\n",
      "2760    Typ\n",
      "2761    Typ\n",
      "Name: functional, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       P\n",
      "1       Y\n",
      "2       Y\n",
      "3       Y\n",
      "4       Y\n",
      "       ..\n",
      "2757    Y\n",
      "2758    Y\n",
      "2759    Y\n",
      "2760    Y\n",
      "2761    Y\n",
      "Name: paveddrive, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       WD \n",
      "1       WD \n",
      "2       WD \n",
      "3       WD \n",
      "4       WD \n",
      "       ... \n",
      "2757    WD \n",
      "2758    WD \n",
      "2759    WD \n",
      "2760    WD \n",
      "2761    WD \n",
      "Name: saletype, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       5\n",
      "1       6\n",
      "2       6\n",
      "3       5\n",
      "4       5\n",
      "       ..\n",
      "2757    6\n",
      "2758    5\n",
      "2759    5\n",
      "2760    5\n",
      "2761    5\n",
      "Name: overallcond, Length: 2762, dtype: object>\n",
      "names = <bound method Series.unique of 0       6\n",
      "1       5\n",
      "2       6\n",
      "3       7\n",
      "4       5\n",
      "       ..\n",
      "2757    6\n",
      "2758    5\n",
      "2759    5\n",
      "2760    5\n",
      "2761    7\n",
      "Name: overallqual, Length: 2762, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "#transform text into numerical data by applying LabelEncoder \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ['mssubclass', 'mszoning', 'street', 'lotshape', 'landcontour',\n",
    "       'lotconfig', 'landslope', 'neighborhood', 'condition1', 'condition2',\n",
    "       'bldgtype', 'housestyle', 'roofstyle', 'salecondition',\n",
    "       'roofmatl', 'exterior1st', 'exterior2nd', 'masvnrtype', 'exterqual',\n",
    "       'extercond', 'foundation', 'heating', 'heatingqc', 'centralair',\n",
    "       'electrical', 'kitchenqual', 'functional', 'paveddrive', 'saletype','overallcond', 'overallqual']\n",
    "\n",
    "\n",
    "# # Label Encoder DataFrame for neighborhood columns\n",
    "# le = LabelEncoder()\n",
    "# df2 = df[['neighborhood']].copy(())\n",
    "# df2['neighborhood_encoded'] = le.fit_transform(list(df['neighborhood'].values))\n",
    "\n",
    "# print(df2.neighborhood_encoded.unique())\n",
    "# print(df2.neighborhood.unique())\n",
    "\n",
    "# Code = [15,8,25,17,2,16,19,0,18,24,23,22,9,3,20,11,4,21,7,5,6,1,14,26,13,27,10,12]\n",
    "# Name = ['NAmes', 'Gilbert', 'StoneBr', 'NWAmes', 'BrDale', 'NPkVill', 'NridgHt',\n",
    "#  'Blmngtn', 'NoRidge', 'Somerst', 'SawyerW', 'Sawyer', 'Greens', 'BrkSide', \n",
    "# 'OldTown', 'IDOTRR', 'ClearCr', 'SWISU', 'Edwards', 'CollgCr', 'Crawfor',\n",
    "#  'Blueste', 'Mitchel', 'Timber', 'MeadowV', 'Veenker', 'GrnHill', 'Landmrk']\n",
    "\n",
    "# df_neighborhood = pd.DataFrame(Code, Name, columns=['Label Encoder'])\n",
    "# df_neighborhood\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# df2 = df[['yrsold']].copy(())\n",
    "# df2['yrsold_encoded'] = le.fit_transform(list(df['yrsold'].values))\n",
    "\n",
    "# print(df2.yrsold_encoded.unique())\n",
    "# print(df2.yrsold.unique())\n",
    "\n",
    "# Code = [4,3,2,1,0]\n",
    "# Name = ['2010', '2009', '2008', '2007', '2006']\n",
    "# df_yrsold = pd.DataFrame(Code, Name, columns=['Label Encoder'])\n",
    "# df_yrsold\n",
    "\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# df2 = df[['overallqual']].copy(())\n",
    "# df2['overallqual_encoded'] = le.fit_transform(list(df['overallqual'].values))\n",
    "\n",
    "# print(df2.overallqual_encoded.unique())\n",
    "# print(df2.overallqual.unique())\n",
    "\n",
    "# Code = [6, 5, 7, 8, 9, 4, 3, 2, 1, 0]\n",
    "# Name = ['6', '5', '7', '8', '9', '4', '3', '2', '10', '1']\n",
    "# df_overallqual = pd.DataFrame(Code, Name, columns=['Label Encoder'])\n",
    "# df_overallqual\n",
    "\n",
    "values = []\n",
    "\n",
    "for col in cols:\n",
    "    \n",
    "    names = df[col].unique\n",
    "    print(f\"names = {names}\")\n",
    "  \n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(df[col].values))\n",
    "    numbers = le.fit_transform(list(df[col].values))\n",
    "    df[col] = numbers\n",
    "    \n",
    "    values.append({\"names\": names, \"numbers\": numbers})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>saleprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526301100</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>526350040</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526351010</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>526353030</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>527105010</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>923275080</td>\n",
       "      <td>142500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>923276100</td>\n",
       "      <td>131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>923400125</td>\n",
       "      <td>132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>924100070</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>924151050</td>\n",
       "      <td>188000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2762 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pid  saleprice\n",
       "0     526301100     215000\n",
       "1     526350040     105000\n",
       "2     526351010     172000\n",
       "3     526353030     244000\n",
       "4     527105010     189900\n",
       "...         ...        ...\n",
       "2757  923275080     142500\n",
       "2758  923276100     131000\n",
       "2759  923400125     132000\n",
       "2760  924100070     170000\n",
       "2761  924151050     188000\n",
       "\n",
       "[2762 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put our selected features into a list\n",
    "\n",
    "cols_8 = [\"neighborhood\",\"total_area\",\"overallqual\", \"garagecars\",\"fullbath\",\"yearbuilt\",\"yearremodadd\",\"yrsold\"]\n",
    "\n",
    "\n",
    "#assign y to our target and x to our features \n",
    "\n",
    "y = df[['pid','saleprice']]\n",
    "X = df\n",
    "X = X.drop(['saleprice'], axis=1)\n",
    "y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 80/20 data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2209, 65), (553, 65), (2209, 2), (553, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data is split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 0)\n",
    "#check the shape of each set\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([177000, 230500, 215700, 203000, 234250, 169000, 118000, 189000,\n",
       "       158000, 151000, 143000, 418000, 221500, 137500, 119000, 139000,\n",
       "       114000, 238000, 163000, 148000, 538000, 243000, 206300, 177000,\n",
       "       255000, 164990, 145000, 185000,  97000,  96000, 108000, 265900,\n",
       "        99500, 145000,  85400, 189000, 136500, 229000, 176432, 215000,\n",
       "       552000, 193000, 104900, 127500, 177625, 224500, 156000, 147000,\n",
       "       100000, 175900, 165000, 260000, 172000, 138400, 232000, 168000,\n",
       "       157000, 159000, 110000,  84900, 189000, 286000, 556581,  88250,\n",
       "       160500, 149500, 137000, 237500, 545224, 129900, 175000, 153500,\n",
       "       148000, 378500, 322400, 200000, 258000, 157500, 127000, 350000,\n",
       "       214500, 155891, 145400, 146500, 460000, 119164, 316500, 109500,\n",
       "       241500, 228000, 116500, 148000, 293000, 213500, 163000, 441929,\n",
       "       157000, 270000, 250000, 170000, 127500, 144000,  37900, 130000,\n",
       "       126500, 207500, 135000, 150000, 213000, 160000, 224500, 133500,\n",
       "       240000, 135960, 127000, 318000, 143000, 132500,  89500, 142000,\n",
       "        60000, 176000,  98000, 426000, 179900, 337000, 159500, 160000,\n",
       "       156500, 154000, 310000, 205000, 138000, 160000, 132000, 181000,\n",
       "       176000, 187000, 142000, 232000, 211000, 173500, 217000, 155000,\n",
       "       140000, 117250, 155000, 212000, 211500,  98000, 136000, 385000,\n",
       "        92000, 119000, 175000, 204000, 209700, 345000, 120000, 130000,\n",
       "       207000, 155000, 122000, 170440, 116000, 215000, 322500, 129500,\n",
       "       203135, 173000, 167000, 184500, 135000, 147000, 149900, 334000,\n",
       "       118000, 298751, 150750, 165500,  95000, 117000, 153000, 127500,\n",
       "        92000, 245000, 156820, 165150, 143000,  83000, 177000, 335000,\n",
       "       387000,  68000, 102000, 115000, 134900, 313000, 137900, 184000,\n",
       "       120000, 184500, 370000, 162500, 318000, 143000,  60000, 108500,\n",
       "       130000, 108000, 172000, 128000, 158000, 284000, 145000, 239500,\n",
       "       147000,  96500, 185485, 332200, 159900, 245000, 131000, 287090,\n",
       "       140000,  90000, 317500, 181755, 227000, 256300, 309000, 412083,\n",
       "       165000,  86000, 184900, 181000, 112000, 122500, 153337, 185000,\n",
       "       143000, 116900, 118000, 120000, 131000, 135900, 115000, 138500,\n",
       "       190000, 290000, 202900,  89500, 257000, 189000, 320000, 118400,\n",
       "       195000, 137000,  64500, 315000, 140000, 345474, 130000, 162000,\n",
       "       106250, 120500, 114000, 466500, 109900, 139000,  93500, 179900,\n",
       "       280000, 120000, 255000, 175000, 181316,  98000, 187500, 114500,\n",
       "        89500, 359900, 270000, 178400, 147000, 131250,  84500, 198000,\n",
       "       132000, 187500, 284000, 341000, 145000,  71000, 350000,  95000,\n",
       "       142500, 274000, 239900, 272500, 212000,  86000, 124000, 110500,\n",
       "       127000, 165000, 127000, 129000, 386250, 201000, 185000, 147000,\n",
       "       185101, 111000, 106500, 192000, 336820, 124000, 141000, 128900,\n",
       "       122600, 112000, 162000, 223000, 219500, 127000, 180500,  97500,\n",
       "       275000, 136500,  93500, 250000, 248500, 108000,  99500, 165500,\n",
       "       130000, 119916, 167800, 165000, 251000, 492000,  90000, 134900,\n",
       "       138500, 126500, 279000, 173000, 179500, 246990, 119500, 114000,\n",
       "       134450,  90000, 174850,  66500, 125000, 144900, 110000, 410000,\n",
       "       208500, 159000, 133000, 260000, 110000, 236000, 330000, 127500,\n",
       "       184000, 324000, 146000, 235876, 584500, 207000, 300000, 245700,\n",
       "       169000, 210000, 370000, 100000,  99900, 132250, 106900, 159000,\n",
       "       475000, 128000, 135500, 120500, 109500, 116500, 135000, 128900,\n",
       "        67500, 119000,  97500, 163500, 124000, 135000, 302000, 173900,\n",
       "       120000, 113000, 127000, 301600, 148000, 157500, 164500, 222000,\n",
       "       118500, 144000, 103500, 168000, 201000, 282000, 234000, 318000,\n",
       "       398800, 135000,  94550, 106000, 138000, 144500, 102000, 230000,\n",
       "       315000, 105000, 184000, 125500, 144000, 161000, 154400, 181000,\n",
       "       269500, 137000, 140000, 293077, 274000, 105000, 149000, 193000,\n",
       "       179600, 135000, 144500, 181134, 130000, 125000, 120000, 205000,\n",
       "       157500, 295000, 152000,  92900, 196000, 319000, 115000, 244400,\n",
       "       200000, 193000,  88750, 159000, 181000,  89500,  78000, 127000,\n",
       "       167500, 221800, 157900, 251000, 190000, 155000,  63900, 165000,\n",
       "       150000, 285000, 110000, 395192, 212500, 240000, 270000,  91300,\n",
       "       187000, 128000, 226000, 132000, 151000, 193000, 180000,  55000,\n",
       "       165000, 147500,  99500, 149500, 139950, 170000,  61500, 209000,\n",
       "       143000, 390000, 126000, 153500, 159900, 282922, 118500, 155000,\n",
       "       117000, 335000, 104000, 174000, 119500, 126500, 172500, 266000,\n",
       "       100000, 160000, 141000, 149000, 205000, 112000, 249000, 240000,\n",
       "       250000,  99800,  83000, 228500, 247900, 111750, 360000, 143900,\n",
       "       222500, 385000, 133700, 118000, 149300, 149900, 154500, 451950,\n",
       "       215000,  67000, 178000, 181000, 176000,  79900, 137000, 217500,\n",
       "       143500, 160000, 174000, 225000, 148000, 136870, 178000, 158000,\n",
       "       268500], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final = y_train['saleprice'].values\n",
    "y_train_final\n",
    "y_test_final = y_test['saleprice'].values\n",
    "y_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2209, 1)\n",
      "(553, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the y values and then print them out\n",
    "y_train_final = y_train_final.reshape(-1, 1)\n",
    "y_test_final = y_test_final.reshape(-1, 1)\n",
    "print(y_train_final.shape)\n",
    "print(y_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit data to our Multiple Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a scaler for the X values and the y values and fit them to the training set\n",
    "X_scaler = preprocessing.StandardScaler().fit(X_train[cols_8])\n",
    "\n",
    "\n",
    "# Scale the training set and the testing set using the new scalers\n",
    "X_train_scaled = X_scaler.transform(X_train[cols_8])\n",
    "X_test_scaled = X_scaler.transform(X_test[cols_8])\n",
    "\n",
    "\n",
    "#Take a log of the target to make it more normally distributed\n",
    "y_train_scaled = np.log(y_train_final)\n",
    "y_test_scaled = np.log(y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2209/2209 [==============================] - 0s 81us/sample - loss: 146.1957\n",
      "Epoch 2/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 127.5434\n",
      "Epoch 3/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 110.3387\n",
      "Epoch 4/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 92.4405\n",
      "Epoch 5/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 73.6693\n",
      "Epoch 6/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 55.9740\n",
      "Epoch 7/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 41.6689\n",
      "Epoch 8/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 31.3912\n",
      "Epoch 9/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 24.5544\n",
      "Epoch 10/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 20.2188\n",
      "Epoch 11/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 17.2924\n",
      "Epoch 12/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 15.1732\n",
      "Epoch 13/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 13.4038\n",
      "Epoch 14/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 11.8462\n",
      "Epoch 15/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 10.4445\n",
      "Epoch 16/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 9.1750\n",
      "Epoch 17/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 7.9877\n",
      "Epoch 18/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 6.9786\n",
      "Epoch 19/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 6.0537\n",
      "Epoch 20/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 5.2545\n",
      "Epoch 21/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 4.5408\n",
      "Epoch 22/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 3.9009\n",
      "Epoch 23/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 3.3615\n",
      "Epoch 24/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 2.8764\n",
      "Epoch 25/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 2.4717\n",
      "Epoch 26/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 2.1294\n",
      "Epoch 27/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 1.8405\n",
      "Epoch 28/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 1.6003\n",
      "Epoch 29/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 1.4051\n",
      "Epoch 30/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 1.2378\n",
      "Epoch 31/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 1.1102\n",
      "Epoch 32/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 1.0033\n",
      "Epoch 33/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.9169\n",
      "Epoch 34/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.8495\n",
      "Epoch 35/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.7853\n",
      "Epoch 36/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.7333\n",
      "Epoch 37/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 0.6888\n",
      "Epoch 38/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.6477\n",
      "Epoch 39/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 0.6123\n",
      "Epoch 40/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 0.5784\n",
      "Epoch 41/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.5475\n",
      "Epoch 42/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.5191\n",
      "Epoch 43/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.4921\n",
      "Epoch 44/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 0.4679\n",
      "Epoch 45/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.4446\n",
      "Epoch 46/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.4219\n",
      "Epoch 47/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.3998\n",
      "Epoch 48/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.3789\n",
      "Epoch 49/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.3580\n",
      "Epoch 50/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.3386\n",
      "Epoch 51/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.3203\n",
      "Epoch 52/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.3009\n",
      "Epoch 53/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.2850\n",
      "Epoch 54/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.2728\n",
      "Epoch 55/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.2513\n",
      "Epoch 56/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.2369\n",
      "Epoch 57/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.2223\n",
      "Epoch 58/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.2102\n",
      "Epoch 59/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.1974\n",
      "Epoch 60/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.2107\n",
      "Epoch 61/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1753\n",
      "Epoch 62/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 0.1648\n",
      "Epoch 63/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1564\n",
      "Epoch 64/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1471\n",
      "Epoch 65/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.1404\n",
      "Epoch 66/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.1337\n",
      "Epoch 67/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1255\n",
      "Epoch 68/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1189\n",
      "Epoch 69/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.1138\n",
      "Epoch 70/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1075\n",
      "Epoch 71/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.1023\n",
      "Epoch 72/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0983\n",
      "Epoch 73/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0935\n",
      "Epoch 74/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0896\n",
      "Epoch 75/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0859\n",
      "Epoch 76/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0830\n",
      "Epoch 77/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0799\n",
      "Epoch 78/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0766\n",
      "Epoch 79/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0742\n",
      "Epoch 80/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0733\n",
      "Epoch 81/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0687\n",
      "Epoch 82/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0665\n",
      "Epoch 83/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0639\n",
      "Epoch 84/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0626\n",
      "Epoch 85/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0604\n",
      "Epoch 86/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0584\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0575\n",
      "Epoch 88/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0559\n",
      "Epoch 89/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0543\n",
      "Epoch 90/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0533\n",
      "Epoch 91/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0516\n",
      "Epoch 92/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0513\n",
      "Epoch 93/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 0.0500\n",
      "Epoch 94/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 0.0486\n",
      "Epoch 95/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0649\n",
      "Epoch 96/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0466\n",
      "Epoch 97/100\n",
      "2209/2209 [==============================] - 0s 19us/sample - loss: 0.0460\n",
      "Epoch 98/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0447\n",
      "Epoch 99/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0440\n",
      "Epoch 100/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0438\n",
      "R^2 for training set: 0.73\n",
      "R^2 for testing set: 0.67\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2209/2209 [==============================] - 0s 103us/sample - loss: 133.0338\n",
      "Epoch 2/100\n",
      "2209/2209 [==============================] - 0s 24us/sample - loss: 111.1885\n",
      "Epoch 3/100\n",
      "2209/2209 [==============================] - 0s 25us/sample - loss: 68.7565\n",
      "Epoch 4/100\n",
      "2209/2209 [==============================] - 0s 25us/sample - loss: 27.7446\n",
      "Epoch 5/100\n",
      "2209/2209 [==============================] - 0s 24us/sample - loss: 14.7549\n",
      "Epoch 6/100\n",
      "2209/2209 [==============================] - 0s 25us/sample - loss: 11.6204\n",
      "Epoch 7/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 9.2877\n",
      "Epoch 8/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 7.4861\n",
      "Epoch 9/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 6.1143\n",
      "Epoch 10/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 5.0595\n",
      "Epoch 11/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 4.2551\n",
      "Epoch 12/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 3.6409\n",
      "Epoch 13/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 3.1408\n",
      "Epoch 14/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 2.7379\n",
      "Epoch 15/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 2.3835\n",
      "Epoch 16/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 2.0929\n",
      "Epoch 17/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 1.8433\n",
      "Epoch 18/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 1.6331\n",
      "Epoch 19/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 1.4524\n",
      "Epoch 20/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 1.2964\n",
      "Epoch 21/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 1.1592\n",
      "Epoch 22/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 1.0459\n",
      "Epoch 23/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.9354\n",
      "Epoch 24/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.8344\n",
      "Epoch 25/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.7434\n",
      "Epoch 26/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.6700\n",
      "Epoch 27/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.6049\n",
      "Epoch 28/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.5464\n",
      "Epoch 29/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.4958\n",
      "Epoch 30/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.4485\n",
      "Epoch 31/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.4063\n",
      "Epoch 32/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.3687\n",
      "Epoch 33/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.3346\n",
      "Epoch 34/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.3051\n",
      "Epoch 35/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.2792\n",
      "Epoch 36/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.2553\n",
      "Epoch 37/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.2347\n",
      "Epoch 38/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.2152\n",
      "Epoch 39/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.1970\n",
      "Epoch 40/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.1829\n",
      "Epoch 41/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1673\n",
      "Epoch 42/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.1538\n",
      "Epoch 43/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.1422\n",
      "Epoch 44/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1343\n",
      "Epoch 45/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1223\n",
      "Epoch 46/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.1148\n",
      "Epoch 47/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1068\n",
      "Epoch 48/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.1004\n",
      "Epoch 49/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0942\n",
      "Epoch 50/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0890\n",
      "Epoch 51/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0817\n",
      "Epoch 52/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0776\n",
      "Epoch 53/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0736\n",
      "Epoch 54/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0705\n",
      "Epoch 55/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0697\n",
      "Epoch 56/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0634\n",
      "Epoch 57/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0604\n",
      "Epoch 58/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0580\n",
      "Epoch 59/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0553\n",
      "Epoch 60/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0536\n",
      "Epoch 61/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0517\n",
      "Epoch 62/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0503\n",
      "Epoch 63/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0482\n",
      "Epoch 64/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0477\n",
      "Epoch 65/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0457\n",
      "Epoch 66/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0447\n",
      "Epoch 67/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0425\n",
      "Epoch 68/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0438\n",
      "Epoch 69/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0413\n",
      "Epoch 70/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0403\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0391\n",
      "Epoch 72/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0383\n",
      "Epoch 73/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0375\n",
      "Epoch 74/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0435\n",
      "Epoch 75/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0368\n",
      "Epoch 76/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0358\n",
      "Epoch 77/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0357\n",
      "Epoch 78/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0351\n",
      "Epoch 79/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0352\n",
      "Epoch 80/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0351\n",
      "Epoch 81/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0335\n",
      "Epoch 82/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0342\n",
      "Epoch 83/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0333\n",
      "Epoch 84/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0333\n",
      "Epoch 85/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0332\n",
      "Epoch 86/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0330\n",
      "Epoch 87/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0328\n",
      "Epoch 88/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0322\n",
      "Epoch 89/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0316\n",
      "Epoch 90/100\n",
      "2209/2209 [==============================] - 0s 20us/sample - loss: 0.0327\n",
      "Epoch 91/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0316\n",
      "Epoch 92/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0324\n",
      "Epoch 93/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0317\n",
      "Epoch 94/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0317\n",
      "Epoch 95/100\n",
      "2209/2209 [==============================] - 0s 23us/sample - loss: 0.0320\n",
      "Epoch 96/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0309\n",
      "Epoch 97/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0319\n",
      "Epoch 98/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0310\n",
      "Epoch 99/100\n",
      "2209/2209 [==============================] - 0s 21us/sample - loss: 0.0310\n",
      "Epoch 100/100\n",
      "2209/2209 [==============================] - 0s 22us/sample - loss: 0.0310\n",
      "R^2 for training set: 0.81\n",
      "R^2 for testing set: 0.83\n",
      "Time to run the model: 0:00:10.020243\n"
     ]
    }
   ],
   "source": [
    "#Compare with Deep Learning Model\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation = \"relu\", input_dim = 8))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "nn_model.summary()\n",
    "nn_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "#time starting time\n",
    "start_1=datetime.now()\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train_scaled, epochs=100)\n",
    "#time ending time\n",
    "end_1=datetime.now()\n",
    "\n",
    "y_train_pred = nn_model.predict(X_train_scaled)\n",
    "y_test_pred = nn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the neural network\n",
    "print(f\"R^2 for training set: {r2_score(y_train_scaled, y_train_pred):.2f}\")\n",
    "print(f\"R^2 for testing set: {r2_score(y_test_scaled, y_test_pred):.2f}\") \n",
    "\n",
    "deep_model = tf.keras.models.Sequential()\n",
    "deep_model.add(tf.keras.layers.Dense(units=8, activation = \"relu\", input_dim = 8))\n",
    "deep_model.add(tf.keras.layers.Dense(units=8, activation = \"relu\"))\n",
    "deep_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "deep_model.summary()\n",
    "\n",
    "deep_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "#start deep learning starting time\n",
    "start_2=datetime.now()\n",
    "deep_model.fit(X_train_scaled, y_train_scaled, epochs=100)\n",
    "#time deep learning ending time\n",
    "end_2=datetime.now()\n",
    "y_train_pred = deep_model.predict(X_train_scaled)\n",
    "y_test_pred = deep_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance and run time of the deep learning model\n",
    "print(f\"R^2 for training set: {r2_score(y_train_scaled, y_train_pred):.2f}\")\n",
    "print(f\"R^2 for testing set: {r2_score(y_test_scaled, y_test_pred):.2f}\")\n",
    "time_taken_neu = end_1 - start_1\n",
    "time_taken_dl = end_2 - start_2\n",
    "total_time = time_taken_dl + time_taken_neu\n",
    "print(f\"Time to run the model: {total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143408.05 ],\n",
       "       [229757.56 ],\n",
       "       [188388.61 ],\n",
       "       [263337.72 ],\n",
       "       [213058.98 ],\n",
       "       [166199.89 ],\n",
       "       [100447.67 ],\n",
       "       [200388.56 ],\n",
       "       [166146.33 ],\n",
       "       [152031.17 ],\n",
       "       [159056.77 ],\n",
       "       [395391.78 ],\n",
       "       [249184.08 ],\n",
       "       [141397.34 ],\n",
       "       [175314.53 ],\n",
       "       [125208.875],\n",
       "       [103872.91 ],\n",
       "       [264486.16 ],\n",
       "       [145064.88 ],\n",
       "       [164204.4  ],\n",
       "       [488649.84 ],\n",
       "       [209123.84 ],\n",
       "       [240410.31 ],\n",
       "       [171373.47 ],\n",
       "       [285987.   ],\n",
       "       [191517.6  ],\n",
       "       [184431.67 ],\n",
       "       [180139.39 ],\n",
       "       [ 90499.82 ],\n",
       "       [102768.445],\n",
       "       [ 92388.67 ],\n",
       "       [238601.55 ],\n",
       "       [118358.65 ],\n",
       "       [150053.61 ],\n",
       "       [123001.59 ],\n",
       "       [180586.27 ],\n",
       "       [128422.71 ],\n",
       "       [242165.36 ],\n",
       "       [180445.95 ],\n",
       "       [192828.16 ],\n",
       "       [241212.73 ],\n",
       "       [195008.7  ],\n",
       "       [122359.75 ],\n",
       "       [175880.56 ],\n",
       "       [164052.88 ],\n",
       "       [237911.02 ],\n",
       "       [153182.66 ],\n",
       "       [140460.03 ],\n",
       "       [128045.555],\n",
       "       [181938.4  ],\n",
       "       [130080.086],\n",
       "       [241127.17 ],\n",
       "       [168059.77 ],\n",
       "       [200195.83 ],\n",
       "       [267928.4  ],\n",
       "       [216721.7  ],\n",
       "       [171237.55 ],\n",
       "       [280688.84 ],\n",
       "       [119080.195],\n",
       "       [ 87458.33 ],\n",
       "       [198166.56 ],\n",
       "       [226596.02 ],\n",
       "       [437620.8  ],\n",
       "       [ 94756.66 ],\n",
       "       [167984.3  ],\n",
       "       [135081.16 ],\n",
       "       [107008.31 ],\n",
       "       [196226.16 ],\n",
       "       [880477.8  ],\n",
       "       [113331.02 ],\n",
       "       [133444.66 ],\n",
       "       [121334.38 ],\n",
       "       [150975.72 ],\n",
       "       [383362.8  ],\n",
       "       [286640.7  ],\n",
       "       [215019.38 ],\n",
       "       [257813.42 ],\n",
       "       [141994.75 ],\n",
       "       [142092.97 ],\n",
       "       [332899.9  ],\n",
       "       [259894.97 ],\n",
       "       [107477.03 ],\n",
       "       [145229.19 ],\n",
       "       [146131.12 ],\n",
       "       [262008.8  ],\n",
       "       [120028.12 ],\n",
       "       [313748.6  ],\n",
       "       [ 90884.52 ],\n",
       "       [201042.81 ],\n",
       "       [223280.7  ],\n",
       "       [117952.09 ],\n",
       "       [153555.94 ],\n",
       "       [276032.7  ],\n",
       "       [211797.06 ],\n",
       "       [167818.08 ],\n",
       "       [308105.3  ],\n",
       "       [175810.8  ],\n",
       "       [197972.19 ],\n",
       "       [270326.38 ],\n",
       "       [183142.72 ],\n",
       "       [127484.33 ],\n",
       "       [157577.75 ],\n",
       "       [ 62818.395],\n",
       "       [124188.65 ],\n",
       "       [132779.97 ],\n",
       "       [180678.42 ],\n",
       "       [126516.61 ],\n",
       "       [134505.52 ],\n",
       "       [185303.31 ],\n",
       "       [181468.28 ],\n",
       "       [219830.38 ],\n",
       "       [117103.41 ],\n",
       "       [241614.72 ],\n",
       "       [149202.72 ],\n",
       "       [124717.99 ],\n",
       "       [293775.   ],\n",
       "       [126447.375],\n",
       "       [136444.5  ],\n",
       "       [100755.16 ],\n",
       "       [141739.45 ],\n",
       "       [ 47417.312],\n",
       "       [177972.97 ],\n",
       "       [ 99219.49 ],\n",
       "       [208742.06 ],\n",
       "       [149465.89 ],\n",
       "       [309915.34 ],\n",
       "       [153888.72 ],\n",
       "       [149515.66 ],\n",
       "       [226451.92 ],\n",
       "       [147665.12 ],\n",
       "       [315496.06 ],\n",
       "       [201573.08 ],\n",
       "       [140582.8  ],\n",
       "       [140237.72 ],\n",
       "       [148816.47 ],\n",
       "       [190767.67 ],\n",
       "       [172610.69 ],\n",
       "       [184124.12 ],\n",
       "       [162156.14 ],\n",
       "       [267147.9  ],\n",
       "       [187580.97 ],\n",
       "       [187701.4  ],\n",
       "       [204349.05 ],\n",
       "       [156067.97 ],\n",
       "       [118896.48 ],\n",
       "       [123295.555],\n",
       "       [156707.94 ],\n",
       "       [200486.42 ],\n",
       "       [184165.56 ],\n",
       "       [129515.38 ],\n",
       "       [130780.64 ],\n",
       "       [299563.22 ],\n",
       "       [133487.05 ],\n",
       "       [ 96949.27 ],\n",
       "       [203180.77 ],\n",
       "       [221024.81 ],\n",
       "       [211735.67 ],\n",
       "       [337904.4  ],\n",
       "       [137731.73 ],\n",
       "       [115973.34 ],\n",
       "       [198057.73 ],\n",
       "       [201782.9  ],\n",
       "       [167308.16 ],\n",
       "       [172336.83 ],\n",
       "       [121265.44 ],\n",
       "       [215357.36 ],\n",
       "       [332805.94 ],\n",
       "       [126780.516],\n",
       "       [201623.83 ],\n",
       "       [159889.73 ],\n",
       "       [172491.23 ],\n",
       "       [183877.05 ],\n",
       "       [151236.7  ],\n",
       "       [149836.69 ],\n",
       "       [156012.9  ],\n",
       "       [268541.06 ],\n",
       "       [140186.5  ],\n",
       "       [261344.73 ],\n",
       "       [164165.56 ],\n",
       "       [175319.56 ],\n",
       "       [105293.25 ],\n",
       "       [ 99092.586],\n",
       "       [155756.77 ],\n",
       "       [151196.61 ],\n",
       "       [101877.516],\n",
       "       [198518.77 ],\n",
       "       [186200.2  ],\n",
       "       [179685.05 ],\n",
       "       [161374.3  ],\n",
       "       [130056.52 ],\n",
       "       [183919.14 ],\n",
       "       [330990.7  ],\n",
       "       [310994.22 ],\n",
       "       [ 82772.695],\n",
       "       [100619.19 ],\n",
       "       [117339.95 ],\n",
       "       [133213.62 ],\n",
       "       [326431.78 ],\n",
       "       [193908.25 ],\n",
       "       [191942.36 ],\n",
       "       [ 99996.63 ],\n",
       "       [192376.31 ],\n",
       "       [318970.97 ],\n",
       "       [200731.69 ],\n",
       "       [282029.38 ],\n",
       "       [159024.92 ],\n",
       "       [ 61833.69 ],\n",
       "       [113949.086],\n",
       "       [128131.914],\n",
       "       [133780.17 ],\n",
       "       [186081.8  ],\n",
       "       [107780.03 ],\n",
       "       [132135.98 ],\n",
       "       [261378.38 ],\n",
       "       [166568.17 ],\n",
       "       [237943.7  ],\n",
       "       [156209.73 ],\n",
       "       [ 97420.47 ],\n",
       "       [188141.73 ],\n",
       "       [311630.75 ],\n",
       "       [175702.19 ],\n",
       "       [227681.27 ],\n",
       "       [116281.664],\n",
       "       [280533.34 ],\n",
       "       [172222.16 ],\n",
       "       [ 94457.74 ],\n",
       "       [265760.47 ],\n",
       "       [181212.33 ],\n",
       "       [198046.4  ],\n",
       "       [276892.2  ],\n",
       "       [318024.22 ],\n",
       "       [393529.28 ],\n",
       "       [163295.06 ],\n",
       "       [ 76647.7  ],\n",
       "       [192675.77 ],\n",
       "       [184604.3  ],\n",
       "       [116787.445],\n",
       "       [111367.22 ],\n",
       "       [146334.17 ],\n",
       "       [207125.33 ],\n",
       "       [127563.38 ],\n",
       "       [119482.09 ],\n",
       "       [114707.51 ],\n",
       "       [132014.81 ],\n",
       "       [138035.75 ],\n",
       "       [111550.16 ],\n",
       "       [120658.305],\n",
       "       [138115.55 ],\n",
       "       [216005.28 ],\n",
       "       [291214.3  ],\n",
       "       [250166.75 ],\n",
       "       [ 85586.32 ],\n",
       "       [276687.34 ],\n",
       "       [218480.42 ],\n",
       "       [264311.16 ],\n",
       "       [120163.266],\n",
       "       [209944.12 ],\n",
       "       [134092.86 ],\n",
       "       [ 77071.516],\n",
       "       [253662.02 ],\n",
       "       [157916.53 ],\n",
       "       [342402.4  ],\n",
       "       [136590.06 ],\n",
       "       [162905.58 ],\n",
       "       [ 97943.266],\n",
       "       [122270.39 ],\n",
       "       [ 86821.92 ],\n",
       "       [240216.42 ],\n",
       "       [ 94594.41 ],\n",
       "       [123412.6  ],\n",
       "       [ 92128.59 ],\n",
       "       [170967.48 ],\n",
       "       [210723.62 ],\n",
       "       [117835.5  ],\n",
       "       [220712.66 ],\n",
       "       [186322.23 ],\n",
       "       [166184.52 ],\n",
       "       [105425.88 ],\n",
       "       [174034.36 ],\n",
       "       [117550.52 ],\n",
       "       [110389.01 ],\n",
       "       [333498.25 ],\n",
       "       [291518.3  ],\n",
       "       [182360.   ],\n",
       "       [167009.1  ],\n",
       "       [129825.91 ],\n",
       "       [147520.16 ],\n",
       "       [211035.94 ],\n",
       "       [126954.625],\n",
       "       [189975.19 ],\n",
       "       [257586.83 ],\n",
       "       [293429.22 ],\n",
       "       [145341.4  ],\n",
       "       [117227.66 ],\n",
       "       [310530.7  ],\n",
       "       [114688.695],\n",
       "       [131196.12 ],\n",
       "       [289230.1  ],\n",
       "       [258566.89 ],\n",
       "       [267408.94 ],\n",
       "       [218752.5  ],\n",
       "       [ 98963.3  ],\n",
       "       [115577.41 ],\n",
       "       [137383.83 ],\n",
       "       [124586.28 ],\n",
       "       [164372.98 ],\n",
       "       [126698.445],\n",
       "       [121133.9  ],\n",
       "       [230894.94 ],\n",
       "       [256879.34 ],\n",
       "       [163355.66 ],\n",
       "       [133238.4  ],\n",
       "       [189018.47 ],\n",
       "       [108999.25 ],\n",
       "       [103239.96 ],\n",
       "       [175089.64 ],\n",
       "       [298562.7  ],\n",
       "       [130653.734],\n",
       "       [138480.23 ],\n",
       "       [137660.3  ],\n",
       "       [137784.28 ],\n",
       "       [120328.74 ],\n",
       "       [155804.45 ],\n",
       "       [202602.23 ],\n",
       "       [213058.98 ],\n",
       "       [119288.766],\n",
       "       [173944.6  ],\n",
       "       [122214.555],\n",
       "       [299813.   ],\n",
       "       [145953.55 ],\n",
       "       [ 79178.945],\n",
       "       [245663.36 ],\n",
       "       [262642.72 ],\n",
       "       [122350.53 ],\n",
       "       [104138.33 ],\n",
       "       [162196.36 ],\n",
       "       [143953.95 ],\n",
       "       [109984.336],\n",
       "       [172112.31 ],\n",
       "       [166131.75 ],\n",
       "       [244657.77 ],\n",
       "       [409832.12 ],\n",
       "       [125251.27 ],\n",
       "       [163183.44 ],\n",
       "       [121141.414],\n",
       "       [140535.61 ],\n",
       "       [201311.61 ],\n",
       "       [175686.44 ],\n",
       "       [142814.08 ],\n",
       "       [202588.89 ],\n",
       "       [132050.2  ],\n",
       "       [ 77680.3  ],\n",
       "       [151826.3  ],\n",
       "       [ 88478.71 ],\n",
       "       [192976.06 ],\n",
       "       [104347.195],\n",
       "       [137801.5  ],\n",
       "       [146128.06 ],\n",
       "       [119948.82 ],\n",
       "       [448708.47 ],\n",
       "       [197219.92 ],\n",
       "       [189887.34 ],\n",
       "       [154137.53 ],\n",
       "       [262347.1  ],\n",
       "       [205088.2  ],\n",
       "       [233924.31 ],\n",
       "       [178204.45 ],\n",
       "       [138326.98 ],\n",
       "       [184850.4  ],\n",
       "       [226919.75 ],\n",
       "       [166571.2  ],\n",
       "       [228730.9  ],\n",
       "       [463708.94 ],\n",
       "       [211685.4  ],\n",
       "       [280727.38 ],\n",
       "       [264499.28 ],\n",
       "       [170085.89 ],\n",
       "       [197237.42 ],\n",
       "       [355672.28 ],\n",
       "       [123325.19 ],\n",
       "       [ 83763.33 ],\n",
       "       [130265.31 ],\n",
       "       [122944.83 ],\n",
       "       [166590.89 ],\n",
       "       [308222.28 ],\n",
       "       [143257.28 ],\n",
       "       [123765.73 ],\n",
       "       [123597.41 ],\n",
       "       [109596.93 ],\n",
       "       [113065.56 ],\n",
       "       [140905.6  ],\n",
       "       [122410.28 ],\n",
       "       [ 93168.45 ],\n",
       "       [117763.49 ],\n",
       "       [136251.8  ],\n",
       "       [172069.14 ],\n",
       "       [196907.77 ],\n",
       "       [165316.23 ],\n",
       "       [231328.48 ],\n",
       "       [176217.36 ],\n",
       "       [132865.1  ],\n",
       "       [140264.33 ],\n",
       "       [138128.45 ],\n",
       "       [252973.27 ],\n",
       "       [144521.23 ],\n",
       "       [148184.27 ],\n",
       "       [156014.7  ],\n",
       "       [187758.16 ],\n",
       "       [125664.89 ],\n",
       "       [154591.83 ],\n",
       "       [138254.72 ],\n",
       "       [178136.16 ],\n",
       "       [209035.5  ],\n",
       "       [312562.38 ],\n",
       "       [205674.64 ],\n",
       "       [336635.22 ],\n",
       "       [402760.9  ],\n",
       "       [119934.63 ],\n",
       "       [ 90291.28 ],\n",
       "       [123070.94 ],\n",
       "       [170248.66 ],\n",
       "       [136884.77 ],\n",
       "       [124986.13 ],\n",
       "       [208568.75 ],\n",
       "       [266358.78 ],\n",
       "       [115180.19 ],\n",
       "       [203759.02 ],\n",
       "       [117282.56 ],\n",
       "       [120989.586],\n",
       "       [207068.45 ],\n",
       "       [141278.72 ],\n",
       "       [188904.05 ],\n",
       "       [366072.25 ],\n",
       "       [139459.23 ],\n",
       "       [134318.75 ],\n",
       "       [279401.56 ],\n",
       "       [216844.5  ],\n",
       "       [107699.27 ],\n",
       "       [142168.73 ],\n",
       "       [177787.55 ],\n",
       "       [204420.   ],\n",
       "       [128924.85 ],\n",
       "       [146145.2  ],\n",
       "       [194927.64 ],\n",
       "       [128382.42 ],\n",
       "       [125166.016],\n",
       "       [134547.34 ],\n",
       "       [209171.5  ],\n",
       "       [174684.36 ],\n",
       "       [290787.22 ],\n",
       "       [144613.88 ],\n",
       "       [ 76151.53 ],\n",
       "       [188877.02 ],\n",
       "       [309985.7  ],\n",
       "       [ 96866.46 ],\n",
       "       [196569.67 ],\n",
       "       [181031.66 ],\n",
       "       [199177.19 ],\n",
       "       [107355.64 ],\n",
       "       [180305.6  ],\n",
       "       [196307.39 ],\n",
       "       [123001.59 ],\n",
       "       [ 79767.99 ],\n",
       "       [125686.22 ],\n",
       "       [402731.3  ],\n",
       "       [242553.89 ],\n",
       "       [156952.78 ],\n",
       "       [272871.44 ],\n",
       "       [194131.22 ],\n",
       "       [145836.81 ],\n",
       "       [ 51019.344],\n",
       "       [153870.95 ],\n",
       "       [194764.86 ],\n",
       "       [254353.38 ],\n",
       "       [114352.53 ],\n",
       "       [358996.9  ],\n",
       "       [203664.22 ],\n",
       "       [218645.72 ],\n",
       "       [226175.88 ],\n",
       "       [ 90446.664],\n",
       "       [219918.86 ],\n",
       "       [164301.98 ],\n",
       "       [206002.86 ],\n",
       "       [147036.14 ],\n",
       "       [168636.94 ],\n",
       "       [178011.16 ],\n",
       "       [188648.03 ],\n",
       "       [ 77444.336],\n",
       "       [147120.3  ],\n",
       "       [134627.69 ],\n",
       "       [ 82852.14 ],\n",
       "       [171535.5  ],\n",
       "       [146275.84 ],\n",
       "       [162783.36 ],\n",
       "       [ 87925.48 ],\n",
       "       [224266.2  ],\n",
       "       [149052.53 ],\n",
       "       [407077.75 ],\n",
       "       [125889.8  ],\n",
       "       [150925.33 ],\n",
       "       [131515.44 ],\n",
       "       [265338.06 ],\n",
       "       [114181.23 ],\n",
       "       [166336.1  ],\n",
       "       [133771.23 ],\n",
       "       [260760.42 ],\n",
       "       [138084.73 ],\n",
       "       [198375.5  ],\n",
       "       [116114.336],\n",
       "       [168982.1  ],\n",
       "       [167135.28 ],\n",
       "       [257776.55 ],\n",
       "       [104144.19 ],\n",
       "       [176367.5  ],\n",
       "       [151874.95 ],\n",
       "       [146110.22 ],\n",
       "       [249048.19 ],\n",
       "       [106717.35 ],\n",
       "       [249068.86 ],\n",
       "       [236657.38 ],\n",
       "       [264190.72 ],\n",
       "       [ 92725.336],\n",
       "       [ 99178.53 ],\n",
       "       [254232.11 ],\n",
       "       [225458.1  ],\n",
       "       [129653.18 ],\n",
       "       [318431.78 ],\n",
       "       [153156.66 ],\n",
       "       [230821.62 ],\n",
       "       [215930.73 ],\n",
       "       [130613.87 ],\n",
       "       [112432.02 ],\n",
       "       [146145.2  ],\n",
       "       [167516.98 ],\n",
       "       [153443.2  ],\n",
       "       [210089.53 ],\n",
       "       [226725.92 ],\n",
       "       [110660.64 ],\n",
       "       [177163.84 ],\n",
       "       [225477.88 ],\n",
       "       [170419.06 ],\n",
       "       [ 95175.52 ],\n",
       "       [119958.195],\n",
       "       [209716.2  ],\n",
       "       [151970.3  ],\n",
       "       [156128.7  ],\n",
       "       [173384.14 ],\n",
       "       [297315.06 ],\n",
       "       [132562.22 ],\n",
       "       [128770.516],\n",
       "       [181752.5  ],\n",
       "       [183116.34 ],\n",
       "       [282586.7  ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred\n",
    "y_test_pred = np.exp(y_test_pred)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df['y_test_pred']= y_test_pred\n",
    "y_test_df\n",
    "y_test_df.rename(columns={0: \"saleprice\"}, inplace=True)\n",
    "y_test_df\n",
    "\n",
    "y_test_df.to_csv('Resources/y_test_vs_pred_dl.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Formula for our multiple linear regression model**\n",
    "\n",
    "y = -2.67021895e-16 + 0.03896429*neighborhood + 0.60886396*total_area + 0.13411633*overallqual + 0.08067865*garagecars + (-0.07035814*fullbath) + 0.16385461*yearbuilt +0.12970701*yearremodadd +(-0.01437204*yrsold) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An example of how we get the result for different number of features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2209, 64)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 8,449\n",
      "Trainable params: 8,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 0s 189us/sample - loss: 90.6158\n",
      "R^2 for training set: -264.00\n",
      "R^2 for testing set: -227.11\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 24,961\n",
      "Trainable params: 24,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 0s 221us/sample - loss: 30.3693\n",
      "R^2 for training set: -24.94\n",
      "R^2 for testing set: -20.35\n",
      "Time to run the model: 0:00:01.264448\n",
      "(2209, 54)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 108)               5940      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 109       \n",
      "=================================================================\n",
      "Total params: 6,049\n",
      "Trainable params: 6,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 0s 213us/sample - loss: 86.9492\n",
      "R^2 for training set: -264.88\n",
      "R^2 for testing set: -230.04\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 108)               5940      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 108)               11772     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 109       \n",
      "=================================================================\n",
      "Total params: 17,821\n",
      "Trainable params: 17,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 235us/sample - loss: 38.1091\n",
      "R^2 for training set: -31.06\n",
      "R^2 for testing set: -28.85\n",
      "Time to run the model: 0:00:01.353177\n",
      "(2209, 44)\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 88)                3960      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 89        \n",
      "=================================================================\n",
      "Total params: 4,049\n",
      "Trainable params: 4,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 0s 218us/sample - loss: 111.0709\n",
      "R^2 for training set: -447.03\n",
      "R^2 for testing set: -391.79\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 88)                3960      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 89        \n",
      "=================================================================\n",
      "Total params: 11,881\n",
      "Trainable params: 11,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 257us/sample - loss: 46.2229\n",
      "R^2 for training set: -38.65\n",
      "R^2 for testing set: -30.61\n",
      "Time to run the model: 0:00:01.426419\n",
      "(2209, 34)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 68)                2380      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 69        \n",
      "=================================================================\n",
      "Total params: 2,449\n",
      "Trainable params: 2,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 240us/sample - loss: 97.5512\n",
      "R^2 for training set: -410.75\n",
      "R^2 for testing set: -355.39\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 68)                2380      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 68)                4692      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 69        \n",
      "=================================================================\n",
      "Total params: 7,141\n",
      "Trainable params: 7,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 278us/sample - loss: 75.5898\n",
      "R^2 for training set: -68.59\n",
      "R^2 for testing set: -54.32\n",
      "Time to run the model: 0:00:01.530987\n",
      "(2209, 24)\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 48)                1200      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 260us/sample - loss: 118.9041\n",
      "R^2 for training set: -593.76\n",
      "R^2 for testing set: -517.21\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 48)                1200      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 3,601\n",
      "Trainable params: 3,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2209/2209 [==============================] - 1s 296us/sample - loss: 88.3478\n",
      "R^2 for training set: -159.14\n",
      "R^2 for testing set: -129.46\n",
      "Time to run the model: 0:00:01.731607\n",
      "(2209, 11)\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 22)                264       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 23        \n",
      "=================================================================\n",
      "Total params: 287\n",
      "Trainable params: 287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 295us/sample - loss: 122.8129\n",
      "R^2 for training set: -688.57\n",
      "R^2 for testing set: -602.83\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 22)                264       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 22)                506       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 23        \n",
      "=================================================================\n",
      "Total params: 793\n",
      "Trainable params: 793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 319us/sample - loss: 102.5875\n",
      "R^2 for training set: -395.15\n",
      "R^2 for testing set: -338.22\n",
      "Time to run the model: 0:00:01.719077\n",
      "(2209, 9)\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             (None, 18)                180       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 308us/sample - loss: 141.4883\n",
      "R^2 for training set: -835.21\n",
      "R^2 for testing set: -740.78\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 18)                180       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 318us/sample - loss: 127.1281\n",
      "R^2 for training set: -645.42\n",
      "R^2 for testing set: -571.22\n",
      "Time to run the model: 0:00:01.788228\n",
      "(2209, 8)\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 322us/sample - loss: 117.1790\n",
      "R^2 for training set: -676.96\n",
      "R^2 for testing set: -591.33\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2209/2209 [==============================] - 1s 354us/sample - loss: 130.7192\n",
      "R^2 for training set: -705.82\n",
      "R^2 for testing set: -622.48\n",
      "Time to run the model: 0:00:01.858783\n"
     ]
    }
   ],
   "source": [
    "cols_64 = ['mssubclass', 'mszoning', 'lotarea', 'street', 'lotshape',\n",
    "       'landcontour', 'lotconfig', 'landslope', 'neighborhood', 'condition1',\n",
    "       'condition2', 'bldgtype', 'housestyle', 'overallqual', 'overallcond',\n",
    "       'yearbuilt', 'yearremodadd', 'roofstyle', 'roofmatl', 'exterior1st',\n",
    "       'exterior2nd', 'masvnrtype', 'masvnrarea', 'exterqual', 'extercond',\n",
    "       'foundation', 'bsmtfinsf1', 'bsmtfinsf2', 'bsmtunfsf', 'totalbsmtsf',\n",
    "       'heating', 'heatingqc', 'centralair', 'electrical', '1stflrsf',\n",
    "       '2ndflrsf', 'lowqualfinsf', 'grlivarea', 'bsmtfullbath', 'bsmthalfbath',\n",
    "       'fullbath', 'halfbath', 'bedroomabvgr', 'kitchenabvgr', 'kitchenqual',\n",
    "       'totrmsabvgrd', 'functional', 'fireplaces', 'garageyrblt', 'garagecars',\n",
    "       'garagearea', 'paveddrive', 'wooddecksf', 'openporchsf',\n",
    "       'enclosedporch', '3ssnporch', 'screenporch', 'poolarea', 'miscval',\n",
    "       'mosold', 'yrsold', 'saletype', 'salecondition','total_area']\n",
    "cols_54 = [\n",
    "       'condition2', 'bldgtype', 'housestyle', 'overallqual', 'overallcond',\n",
    "       'yearbuilt', 'yearremodadd', 'roofstyle', 'roofmatl', 'exterior1st',\n",
    "       'exterior2nd', 'masvnrtype', 'masvnrarea', 'exterqual', 'extercond',\n",
    "       'foundation', 'bsmtfinsf1', 'bsmtfinsf2', 'bsmtunfsf', 'totalbsmtsf',\n",
    "       'heating', 'heatingqc', 'centralair', 'electrical', '1stflrsf',\n",
    "       '2ndflrsf', 'lowqualfinsf', 'grlivarea', 'bsmtfullbath', 'bsmthalfbath',\n",
    "       'fullbath', 'halfbath', 'bedroomabvgr', 'kitchenabvgr', 'kitchenqual',\n",
    "       'totrmsabvgrd', 'functional', 'fireplaces', 'garageyrblt', 'garagecars',\n",
    "       'garagearea', 'paveddrive', 'wooddecksf', 'openporchsf',\n",
    "       'enclosedporch', '3ssnporch', 'screenporch', 'poolarea', 'miscval',\n",
    "       'mosold', 'yrsold', 'saletype', 'salecondition','total_area']\n",
    "cols_44 = [\n",
    "       'condition2', 'bldgtype', 'housestyle', 'overallqual', 'overallcond',\n",
    "       'yearbuilt', 'yearremodadd', 'roofstyle', 'roofmatl', 'exterior1st',\n",
    "       'heating', 'heatingqc', 'centralair', 'electrical', '1stflrsf',\n",
    "       '2ndflrsf', 'lowqualfinsf', 'grlivarea', 'bsmtfullbath', 'bsmthalfbath',\n",
    "       'fullbath', 'halfbath', 'bedroomabvgr', 'kitchenabvgr', 'kitchenqual',\n",
    "       'totrmsabvgrd', 'functional', 'fireplaces', 'garageyrblt', 'garagecars',\n",
    "       'garagearea', 'paveddrive', 'wooddecksf', 'openporchsf',\n",
    "       'enclosedporch', '3ssnporch', 'screenporch', 'poolarea', 'miscval',\n",
    "       'mosold', 'yrsold', 'saletype', 'salecondition','total_area']\n",
    "cols_34 = [\n",
    "       'overallqual', 'overallcond',\n",
    "       'yearbuilt', 'yearremodadd', '1stflrsf',\n",
    "       '2ndflrsf', 'lowqualfinsf', 'grlivarea', 'bsmtfullbath', 'bsmthalfbath',\n",
    "       'fullbath', 'halfbath', 'bedroomabvgr', 'kitchenabvgr', 'kitchenqual',\n",
    "       'totrmsabvgrd', 'functional', 'fireplaces', 'garageyrblt', 'garagecars',\n",
    "       'garagearea', 'paveddrive', 'wooddecksf', 'openporchsf',\n",
    "       'enclosedporch', '3ssnporch', 'screenporch', 'poolarea', 'miscval',\n",
    "       'mosold', 'yrsold', 'saletype', 'salecondition','total_area']\n",
    "cols_24 = [\n",
    "       'overallqual', 'overallcond',\n",
    "       'yearbuilt', 'yearremodadd', '1stflrsf',\n",
    "       '2ndflrsf', 'lowqualfinsf', 'grlivarea', 'bsmtfullbath', 'bsmthalfbath',\n",
    "       'fullbath', 'halfbath', 'garagecars',\n",
    "       'garagearea', \n",
    "       'enclosedporch', '3ssnporch', 'screenporch', 'poolarea', 'miscval',\n",
    "       'mosold', 'yrsold', 'saletype', 'salecondition','total_area']\n",
    "\n",
    "cols_15 = [\"total_area\",\"overallqual\",\"grlivarea\", \"garagecars\",\"garagearea\",\"totalbsmtsf\",\"1stflrsf\",\"fullbath\",\"totrmsabvgrd\", \"yearbuilt\",\"yearremodadd\"]\n",
    "\n",
    "cols_11 = [\"lotconfig\", \"neighborhood\", \"bldgtype\", \"foundation\",\"total_area\",\"overallqual\",\"totrmsabvgrd\", \"yearbuilt\",\"yearremodadd\"]\n",
    "\n",
    "cols_8 = [\"neighborhood\",\"total_area\",\"overallqual\", \"garagecars\",\"fullbath\",\"yearbuilt\",\"yearremodadd\",\"yrsold\"]\n",
    "\n",
    "n = [cols_64,cols_54,cols_44,cols_34,cols_24, cols_15, cols_11, cols_8]\n",
    "# #assign y to our target and x to our features \n",
    "\n",
    "for i in n:\n",
    "    y = df['saleprice'].values\n",
    "    X = df[i]\n",
    "    #data is split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 0)\n",
    "    #check the shape of each set\n",
    "    X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "    print(X_train.shape)\n",
    "    # Define a scaler for the X values and the y values and fit them to the training set\n",
    "    X_scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "\n",
    "    # Scale the training set and the testing set using the new scalers\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    #Take a log to normalize the target\n",
    "    y_train_scaled = np.log(y_train)\n",
    "    y_test_scaled = np.log(y_test)\n",
    "\n",
    "    # Reshape the y values and then print them out\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    #Compare with Deep Learning Model\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    nn_model.add(tf.keras.layers.Dense(units=len(X.columns) * 2, activation = \"relu\", input_dim = len(X.columns)))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "    nn_model.summary()\n",
    "    nn_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "    #time starting time\n",
    "    start_1=datetime.now()\n",
    "\n",
    "    nn_model.fit(X_train_scaled, y_train_scaled, epochs=1)\n",
    "    #time ending time\n",
    "    end_1=datetime.now()\n",
    "\n",
    "    y_train_pred = nn_model.predict(X_train_scaled)\n",
    "    y_test_pred = nn_model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the performance of the neural network\n",
    "    print(f\"R^2 for training set: {r2_score(y_train_scaled, y_train_pred):.2f}\")\n",
    "    print(f\"R^2 for testing set: {r2_score(y_test_scaled, y_test_pred):.2f}\") \n",
    "\n",
    "    deep_model = tf.keras.models.Sequential()\n",
    "    deep_model.add(tf.keras.layers.Dense(units=len(X.columns) * 2, activation = \"relu\", input_dim = len(X.columns)))\n",
    "    deep_model.add(tf.keras.layers.Dense(units=len(X.columns) * 2, activation = \"relu\"))\n",
    "    deep_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "    deep_model.summary()\n",
    "\n",
    "    deep_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "    #start deep learning starting time\n",
    "    start_2=datetime.now()\n",
    "    deep_model.fit(X_train_scaled, y_train_scaled, epochs=1)\n",
    "    #time deep learning ending time\n",
    "    end_2=datetime.now()\n",
    "    y_train_pred = deep_model.predict(X_train_scaled)\n",
    "    y_test_pred = deep_model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the performance and run time of the deep learning model\n",
    "    print(f\"R^2 for training set: {r2_score(y_train_scaled, y_train_pred):.2f}\")\n",
    "    print(f\"R^2 for testing set: {r2_score(y_test_scaled, y_test_pred):.2f}\")\n",
    "    time_taken_neu = end_1 - start_1\n",
    "    time_taken_dl = end_2 - start_2\n",
    "    total_time = time_taken_dl + time_taken_neu\n",
    "    print(f\"Time to run the model: {total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d761b37f2ede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = np.exp(y_test_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df['y_test_pred']= y_pred\n",
    "y_test_df\n",
    "y_test_df.rename(columns={0: \"saleprice\"}, inplace=True)\n",
    "y_test_df\n",
    "\n",
    "y_test_df.to_csv('Resources/y_test_vs_pred_dl.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph the relationship between y_test and t_test_pred\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Multiple Linear Regression VS Deep Learning in terms of model running time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>MLR_R^2</th>\n",
       "      <th>MLR^Run_Time</th>\n",
       "      <th>DL_R^2</th>\n",
       "      <th>DL_Run_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.91</td>\n",
       "      <td>12.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.89</td>\n",
       "      <td>12.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.87</td>\n",
       "      <td>12.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.81</td>\n",
       "      <td>12.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.82</td>\n",
       "      <td>12.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.88</td>\n",
       "      <td>12.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.89</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.89</td>\n",
       "      <td>12.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features  MLR_R^2  MLR^Run_Time  DL_R^2  DL_Run_Time\n",
       "0        64     0.90         0.006    0.91        12.12\n",
       "1        54     0.90         0.003    0.89        12.38\n",
       "2        44     0.89         0.003    0.87        12.18\n",
       "3        34     0.88         0.003    0.81        12.53\n",
       "4        24     0.86         0.003    0.85        12.31\n",
       "5        15     0.85         0.002    0.82        12.44\n",
       "6        11     0.85         0.002    0.88        12.71\n",
       "7         9     0.85         0.002    0.89        12.80\n",
       "8         8     0.86         0.002    0.89        12.38"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the recording of the model run time and model result\n",
    "data = pd.read_csv('Resources/run_time_r2.csv')\n",
    "data = data.dropna()\n",
    "data\n",
    "data['MLR_R^2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.12, 12.38, 12.18, 12.53, 12.31, 12.44, 12.71, 12.8 , 12.38])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DL_Run_Time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MLR points \n",
    "x1 = [64,54,44,34,24,15,11,9,8] \n",
    "y1 = [0.006, 0.003, 0.003, 0.003, 0.003, 0.002, 0.002, 0.002, 0.002] \n",
    "# plotting the line 1 points  \n",
    "plt.plot(x1, y1, label = \"Multiple Linear Regression\") \n",
    "  \n",
    "# DL points \n",
    "x2 = [64,54,44,34,24,15,11,9,8] \n",
    "y2 = [12.12, 12.38, 12.18, 12.53, 12.31, 12.44, 12.71, 12.8 , 12.38] \n",
    "# plotting the DL points  \n",
    "plt.plot(x2, y2, label = \"Deep Learning\") \n",
    "  \n",
    "# naming the x axis \n",
    "plt.xlabel('Num of Features') \n",
    "# naming the y axis \n",
    "plt.ylabel('Model Runtime') \n",
    "# giving a title to my graph \n",
    "plt.title('MLR VS DL Runtime') \n",
    "  \n",
    "# show a legend on the plot \n",
    "plt.legend() \n",
    "  \n",
    "# function to show the plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Multiple Linear Regression VS Deep Learning in terms of R^2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c6aa5938c8>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVfr48c9DQu81AUKvQigqCggoKiq4KNjF8l11XcWKu7q2r2v3u+5vV1cUVkVXsSDYwIIFGyiCIL0LstSAQOgIgbTn98e5wSFMkkmYmTszed6v17wyc+tzJzPz3HvOPeeIqmKMMcYUVsHvAIwxxsQmSxDGGGOCsgRhjDEmKEsQxhhjgrIEYYwxJihLEMYYY4KyBBGjRERFpG0x85eJSP8Qt7VORAaELTi3zRdE5K/h3GZ5JCL9RGSl33GY0hORK0XkC7/jiCRLEGHm/Rhni0iDQtMXej/6LcuwzbEi8njgNFXtrKrTjinYkvfbX0Qygs1T1eGq+lgk9x8q7z3PEpFfRWSL937V8DuuUKjqdFXtEM5tikgVEdktImcEmfcvEXnPe95XRGaKyB4R2SkiM0TkpCK2+bCI5IjIPu+xSkRGiUjjcMYeqpJOoKJBVcep6tl+xhBpliAiYy0wrOCFiHQBqvoXTmIQp6jP7HmqWgPoDhwP3BeB/SeHe5uRoKoHgbeB/wmcLiJJuM/layJSC5gMPAfUA5oCjwCHitn026pa01v+AiAVmOdXkoikEj5r5Ua5fwMi5A2O/HL+Hng9cAERmSYi1we8vkZEvi+8IRG5AbgSuNs7Q/7Ym3642Mg7u3tPRN72zu7mi0i3YIGJSAURuVdE/isiO0TkHRGpV9oDDLyqKbjSEJE7RWSbiPwiItcGLFtZRP4pIhtEZKtXPFXVm1dXRCaLSKaI7PKepxV6n54QkRnAAaB1cXGp6hZgCi5RFGyjl3emvFtEFgUWzYlIKxH5znvfvhKR0SLypjevpXem+gcR2QB8402/TkRWePFOEZEW3nTxztC3eWfli0Uk3Zt3rogs9/azSUTuCnzvAuI5zjvm3eKKEc8v9J6PFpFPvO3MFpE2RbwVrwEXiUi1gGnn4L7znwHtvfdrvKrmqWqWqn6hqouLe3+9dXJUdRlwGZAJ3BkQ42BxV8u7vfe8a8C8JiLyvve/XisitwfMC/kzXJxwf9a8//9wEfnZW2e0iIi3/BHf2RKWTRKRp0Rku3fst3rLx/RJhyWIyJgF1PK+7Em4L9KbZdmQqo4BxgH/T1VrqOp5RSw6BHgXd3b3FvCBiFQMstztwFDgNKAJsAsYXZbYCkkFauPORP8AjBaRut68v+N+kLoDbb1lHvTmVQBeBVoAzYEsYFShbV8N3ADUBNYXF4T3hR8ErPZeNwU+AR7HvTd3Ae+LSENvlbeAH4H6wMPevgo7DTgOOEdEhgL3AxcCDYHpwHhvubOBU71jrYP7v+/w5v0HuNE7A0/HSzaFYq8IfAx8ATQCbgPGiUhgEdQw3Jl+Xe8Ynwj2PqjqTOAXL84CVwNvqWousArIE5HXRGRQwP8qZKqaB3wI9PPiPwF4BbgR936+CHzk/WhX8I5tEe7/fyZwh4icE7DJUD/DxYnEZ20wcBLQDbgUl2iLUtSyf8R9LrsDJ+C+g7FPVe0RxgewDhgAPAD8DRgIfAkkAwq09JabBlwfsN41wPcBrxVo6z0fCzwebD/e84eBWQHzKuB+HPoFWXYFcGbAso2BHCA5yLH0BzKKOM7DMXnLZQVuA9gG9AIE2A+0CZjXG1hbxHa7A7sCXk8DHg3hPf8V2Oe9b18Ddbx59wBvFFp+Cu6qrjmQC1QLmPcm8Kb3vKW3vdYB8z8D/lDovT6A+9E5A/fD2wuoUGifG3A/nLWKeo9xP7RbAtfFJZ+HA97zlwPmnQv8VMz78gDwhfe8lhfn8QHzj/O2meG9Dx8BKUVs6+GC96XQ9OHAz97z54HHCs1fiUuwPYENhebdB7waymc4yH4Pfz8CpoX9s+btp2/A63eAe4v5zha17De4E4SCeQO85Y/63sXSw64gIucN4Arch+j14hcNi40FT1Q1H/elbxJkuRbAJK8IYDcuYeQBKce4/x3qzkwLHABq4M6yq+HKqgv2+bk3HRGpJiIvish6EdkLfAfU8a68jjq2YgxVd3beH+gIFNwk0AK4pGDf3v774hJjE2Cnqh4oYV+B01oAIwO2tRP3w9RUVb/BnZGOBraKyBhxZf0AF+F+0NeLyLci0jvIfpoAG73/X4H1uLPgAlsCnhe8x0V5HTjdu4q6GFitqgsKZqrqClW9RlXTcFc1TYBnitleME1x7wG49+bOQu91M2+7LYAmhebdz5Gfu1A/w0WJ1GetNO95Ucs2KbTtUD7TvrMEESGquh5XWX0uMDHIIvtxH+YCqcVtLoRdNit44l3OpwGbgyy3ERikqnUCHlVUdVMI+yiL7biri84B+6utrkIZXPl1B6CnqtbCFdGA+9EtEHKXw6r6Le6s+J/epI24K4jA462uqk/izlDrFSqnb8bRAve/EXcmGLi9quqKdFDVZ1X1RKAzrqjjL970Oao6BFd09AHu7LKwzUAzObJytDlQpv+Nqm7AFYFdiSs6KfJERVV/wr1v6aFu34vzPG8f4N6bJwq9N9VUdbw3b22heTVV9dyATYb6GS5KVD9rpfQL7ngKBPucxRxLEJH1B+AMVd0fZN5C4ELvrKatt2xRtlJC5Sxwoohc6FV63YG7G2VWkOVeAJ6Q3ypWG4rIkOI2LO62ycCHFLd8IO9M8CXgXyLSyNte04Cy55q4L/VucZXlD4W67WI8A5wlIt1xRUbnicg5XkVhFXEVw2leEp8LPCwilbyz+qLqeAq8ANwnIp29Y6ktIpd4z08SkZ5eufl+4CCunL+SuHvma6tqDrAXd9VW2GxvvbtFpKK4yvTzgAnH8F68BtwK9MHVZeHF2lHcTQVp3utmuPqNYJ+ZI3ixHYcr/koFnvZmvQQM994DEZHqIvI7EamJq+fZKyL3iEhV73+RLkfeVhvqZ7hApcDPJe6HPtqftVC9A4zw4qmDK/qMeZYgIkhV/6uqc4uY/S8gG/fj/xoBX94g/gN08i6bPyhimQ9xlaK7cGeLF3o/RoWNxJU1fyEi+3BfwJ7F7Lsp7ksV+Cjqzpmi3IOrUJ3lXdp/hTuTA/djXhV39jcLVyRwTFQ1E3e2/FdV3Yir/Lwfd8fNRtxZfcFn/0pcOfUOXEX22xRzq6eqTsJVhE7wjmUprvIRXDn/S7j/wXpvmwVXMlcD67x1hgNXBdl2NnC+t73twL+B//HO7svqPVyF9teq+kvA9H24//tsEdmPe++XEnBHUhCXicivwG7cZ2gHcKKqbvbin4urjB2Few9W44pYUVehfR6u3H+td3wv425sKBDqZ7jAMo78XF5LlD9rpfAS7uaDxcAC4FNcvU+wE4WYIV6FiYljIvIwrsLuqB8dUzoi8jau4jeaZ5flXnn7DIvIIOAFVW3hdyzFsSsIU655xUJtxLUPGYi72ijqKs2YMvGK1c4VkWTvpoGHgEl+x1USSxCmvEvF3d74K/AscFPgnT7GhIng2q/swhUxreC39hkxy4qYjDHGBGVXEMYYY4KK6X5ASqtBgwbasmVLv8Mwxpi4MW/evO2q2jDYvIRKEC1btmTu3KLuKjXGGFOYiBTZv5kVMRljjAnKEoQxxpigLEEYY4wJKqHqIILJyckhIyODgwcP+h1KRFSpUoW0tDQqVixtt/nGGFO8hE8QGRkZ1KxZk5YtW1KKPubigqqyY8cOMjIyaNWqld/hGGMSTMIXMR08eJD69esnXHIAEBHq16+fsFdHxhh/JXyCABIyORRI5GMzxvirXCQIY4xJWBtmw4yREdm0JYgoEBGuvvrqw69zc3Np2LAhgwcPBmDs2LHceuutR63XsmVLunTpQteuXTnttNNYv77I9izGmPImPw++/Qe8OgjmvgrZwcYlOzaWIKKgevXqLF26lKysLAC+/PJLmjZtWsJaztSpU1m8eDH9+/fn8ccfj2SYxph4sWcTvHY+TH0cOl8AN34LlaqHfTeWIKJk0KBBfPLJJwCMHz+eYcOGlWr93r17s2lTpIaNNsbEjZ8+hRf6wOYFMOTfcNHLUKV2yeuVQcLf5hrokY+XsXzz3rBus1OTWjx0XucSl7v88st59NFHGTx4MIsXL+a6665j+vTpJa5X4PPPP2fo0KHHEqoxJp7lHIQv/wo/joHUrnDxK9CgXUR3Wa4ShJ+6du3KunXrGD9+POeee27I651++uls3bqVRo0aWRGTMeVV5kp47zrYuhR63QIDHoLkyhHfbblKEKGc6UfS+eefz1133cW0adPYsWNHSOtMnTqV6tWrc8011/Dggw/y9NNPRzhKY0zMUIX5r8Nn97g6hivehfZnR2335SpB+O26666jdu3adOnShWnTpoW8XtWqVXnmmWfo0qULDzzwAPXq1YtckMaY2JC1Gz4eAcs/gFanwYVjoGZqVEOwSuooSktLY8SIEUHnjR07lrS0tMOPjIyMI+Y3btyYYcOGMXr06GiEaozx04bZ8EI/+GkyDHgYrv4g6skBEmxM6h49emjhAYNWrFjBcccd51NE0VEejtGYciE/D75/Gqb+DWqnuYrotB4R3aWIzFPVoDuxIiZjjIkFezfDxBtg3XRIvwgG/ytit6+GyhKEMcb47adP4cObIfeQa9vQ/QqIgX7WLEEYY4xfjmjb0AUufjXibRtKwxKEMcb44Yi2DTe7yugotG0oDUsQxhgTTUe0bagGV7wD7c/xO6qgLEEYY0y0xEDbhtKwdhBRkJSURPfu3encuTPdunXj6aefJj8/H4Bp06Yd7vbbGJPACto2rPgYznzIt7YNpWFXEFFQtWpVFi5cCMC2bdu44oor2LNnD4888ojPkRljIq5w24brpkCzk/yOKiQRvYIQkYEislJEVovIvUHm1xWRSSKyWER+FJH0UNeNV40aNWLMmDGMGjWKRGqkaIwJYu9meH0IfPM4dB4Kw6fHTXKACF5BiEgSMBo4C8gA5ojIR6q6PGCx+4GFqnqBiHT0lj8zxHVL77N7YcuSY9rEUVK7wKAnS7VK69atyc/PZ9u2beGNxRgTO1Z+Bh/cDLkHY6ptQ2lEsojpZGC1qq4BEJEJwBAg8Ee+E/A3AFX9SURaikgK0DqEdeOaXT0YEx2HcvOY+lMmkxdvZuf+7Ijvr6JmM2zPywzc/yHrKrbhubr38cvcZjB3dsT2WbtqRZ6/6sSwbzeSCaIpsDHgdQbQs9Ayi4ALge9F5GSgBZAW4roAiMgNwA0AzZs3Lz6iUp7pR8qaNWtISkqiUaNGrFixwu9wjEk4qsr8DbuYOH8Tkxf/wp6sHBrUqESrBuEfljNQ09wN3LH7SVrmrmVytaGMq3ktuVIJ8vIjut+cvMiccEYyQQS7lip8FE8CI0VkIbAEWADkhrium6g6BhgDrrO+MkcbJZmZmQwfPpxbb70VibPLTWNi3fod+5k4fxMfLNzE+h0HqFKxAmd3SuWCE5rSr20DkpMiVO2qCgve8No2VIVL32Fw+3OI9/sTI5kgMoBmAa/TgM2BC6jqXuBaAHG/lmu9R7WS1o0nWVlZdO/enZycHJKTk7n66qv585//fHj+119/TVpa2uHX7777Lr179/YjVGPizu4D2Uxe/AuTFmxi3vpdiEDv1vW59fS2DExPpWaVipENIGs3TL4Dlk2CVqfCBWOgVuPI7jNKIpkg5gDtRKQVsAm4HLgicAERqQMcUNVs4HrgO1XdKyIlrhtP8vLyipzXv39/srKyohiNMfGvoF5h0oIMpv6USXZePu1TanDPwI4M6d6EJnWqRieQDbPh/eth7ybXtqHPCKiQFJ19R0HEEoSq5orIrcAUIAl4RVWXichwb/4LwHHA6yKSh6uA/kNx60YqVmNM7Ater1CZq3q14MITmtK5Sa3oFdse0bahaVy1bSiNiDaUU9VPgU8LTXsh4PkPQNCuC4Ota4wpf9bv2M+kBZuYtCDK9QpFCRy3ofOFcN4zvo/bECnloiW1qiZshbDdLmsSke/1CkU5om3DaOh+Zdy1bSiNhE8QVapUYceOHdSvXz/hkoSqsmPHDqpUqeJ3KMYcs2D1Cu0a1eDugR0Y2r1p9OoVgsk5CF8+CD++GJPjNkRKwieItLQ0MjIyyMzM9DuUiKhSpcoRd0AZE09cvcJuJi3IYPLiX9h9wLVX8KVeoSiB4zb0vAnOeiTmxm2IlIRPEBUrVqRVq1Z+h2GMCVBQr/DBgk2si4V6hWAC2zZUrArD3oYOA/2OKqoSPkEYY2JDUfUKt/hdrxBMArdtKA1LEMaYiInpeoWiJHjbhtKwBGGMCau4qFcIppy0bSgNSxDGmLAoXK9QObkC53SOsXqFopSjtg2lYQnCGFNmew7kMHnJZibO/61eoVer+tx8elsGxVq9QlFWfg4f3OTaNpw/Co6/KqHbNpSGJQhjTKlk5+YzdeU2Js3fxDc/bYuPeoVgcg7CVw/B7BcgpQtc/Ao0bO93VDHFEoQxpkRxW69QlMxVXtuGJa5tw4CHoaI1OC3MEoQxpkgbdhxg4oKMI+oVzu6cyoXxUK8QTGDbhuQq5bJtQ2lYgjDGHKGgXmHS/E3Mjdd6hWCydsPkP8GyidCyH1z4Urls21AaliAAnmwOOUHGZEhJh2s+gUrVoh+TMVGUMPUKRdn4I7z/B9izCc58EPrcUW7bNpSGJQiAk2+E/Jwjp2UfcB1zzRoNp/7Fn7iMiaCi6hWu7NWci05Ii796hWDy8+D7f8HU/7O2DWVgCQLgjP8NPn3vJvh+JJxwDdRoGNWQjImUDTsOeOMrZBxZr3B8U/q1i8N6haIc0bbhAhj8DFSt43dUccUSRHEGPAyje8K3T8LvnvI7GmPKLGHrFYpibRvCwhJEcRq0gx7XwtxXoefwctH/u0kcCV+vEIy1bQgrSxAlOe0eWDQBvnoYLh/ndzTGFKu4eoULj08jvWkC1CsUxdo2hJ0liJLUaOTueJj6OKz/AVr09jsiY45SbuoVgrG2DRFjCSIUvW+Buf+BL/8Kf/jSyjJNTCh39QrBHNwDH99hbRsixBJEKCpVg9P/Fz66FZZ/CJ2H+h2RKafKZb1CUTbOgfevs7YNEWQJIlTdr4BZ/3Z1ER3OheRKfkdkyolyXa8QTH4ezHgGvnnC2jZEmCWIUFVIgrMehXEXw9xXoNdwvyMyCa5c1ysUZe8vMOkGWPudjdsQBZYgSqPtAGh1Gnz7d+h2uTW6MWFXuF4BoFfreuWrXqEo1rYh6ixBlIYInP0YvHiqu8Qd8LDfEZkEEKxeoW2jGvzlnA4MPb4pTctTvUIwuYfgywcD2jb8Bxp28DuqcsESRGk17gZdL4NZz8NJ10PtNL8jMnHI6hVClLnKVURvWeIaqw54xNo2RJEliLI44wFY9gF88zhc8ILf0Zg4Uly9Qt92DahYHusVglGFBW/CZ3d7bRsmQIdBfkdV7liCKIs6zV0l9YxnodfN0Lir3xGZGGb1CqV0VNuGMVCrid9RlUslJggR+VpVzyxpWrnT988w/3VXNvo/H/gdjYkx2bn5TFu5jYlWr1A6gW0bzvgr9P2TtW3wUZEJQkSqANWABiJSFygoEK0FhJTORWQgMBJIAl5W1ScLza8NvAk092L5p6q+6s37E3A9oMAS4FpVPRj6oUVY1Tpw6t0w5T5Y/ZW7w8mUa6rKgo27mTR/E5MXb2aX1SuELj8fZvzLtW2o1RSu+xyanex3VOVecVcQNwJ34JLB/IDpe4HRJW1YRJK85c4CMoA5IvKRqi4PWOwWYLmqniciDYGVIjIOaAjcDnRS1SwReQe4HBgb8pFFw0nXu0GFvngQWp9uZzrlVEG9wgcLN7F2+36rVyitvb/ApBth7bc2bkOMKTJBqOpIYKSI3Kaqz5Vh2ycDq1V1DYCITACGAIEJQoGa4k6ragA7gdyA2KqKSA7uSmZzGWKIrORKcOZD8N61sGi8uy/blAv7Dubw0aKj6xVu6t/G6hVKY9UU17YhJwvOfw6Ov9raNsSQUCqpXxGRB4DmqnqDiLQDOqjq5BLWawpsDHidAfQstMwo4CPcj39N4DJVzQc2icg/gQ1AFvCFqn4RQqzR1/kCmPmcq7C2BFEuzFm3kxHjF7B5z0GrVyir3EPw5UMw+3lr2xDDQkoQwDzgFO91BvAuUFKCCHYaoIVenwMsBM4A2gBfish0XJ3FEKAVsBt4V0SuUtU3j9qJyA3ADQDNmzcP4XDCTATaD4Rpf4Ps/VCpevRjMFGRl6+M+mY1I79eRbN61Xjnxt6c1LKu1SuU1vaf3VW3tW2IeaEUjrZR1f8H5ACoahbBf/wLywCaBbxO4+hiomuBieqsBtYCHYEBwFpVzVTVHGAivyWoI6jqGFXtoao9Gjb0adzo1HRAYevyEhc18emXPVkMe2kW//pqFed3a8Lk2/pycqt6lhxKo6Btw4unuruUhk2AQX+35BDDQrmCyBaRqnhn/yLSBjgUwnpzgHYi0grYhKtkvqLQMhuAM4HpIpICdADW4BJQLxGphitiOhOYG8I+/ZGS7v5uXWK9SiagKcu2cM/7i8nOzefpS7tx4QnWer7UDu6ByX+Cpe9b24Y4EkqCeAj4HGjm3WHUB7impJVUNVdEbgWm4IqMXlHVZSIy3Jv/AvAYMFZEluCSwj2quh3YLiLv4e6eygUWAGNKe3BRU6c5VK4NW5b6HYkJo4M5eTzxyQremLWe9Ka1eG7YCbRqYEWIpWZtG+KWqBauFgiykEh9oBfuR3yW9yMec3r06KFz5/p0ofHKINA8+ENs1qWb0lm1dR+3vbWAlVv38cd+rfjLOR2plGy3q5ZK4bYNF//H2jbEIBGZp6o9gs0rrqFcC2C3qu5R1R0icgAYCrQXkVGqmh2heONTSmd3q2t+PlSwH5J4paqM/3Ejj05eRo3KyYy99iT6d2jkd1jxx9o2JITifsneAaoDiEh33J1LG4BuwL8jH1qcSU2H7F9h9zq/IzFltOdADjePm8/9k5ZwUst6fDqinyWHslg1BV7oAxlzXNuGi1+15BCniquDqKqqBXcdXYWrQ3hKRCrgbk01gVK6uL9blkK91v7GYkqtoG3Dtn2HuG9QR/7YrzUVKtgdSqVibRsSTnEJIvDbcQZwH4Cq5tutfUE0Og6kAmxdBp3O9zsaE6LAtg1pdavx3k2n0L2Zne2WmrVtSEjFJYhvvD6QfgHqAt8AiEhjwOofCqtUDeq1ga12J1O8+GVPFiMmLOTHtTsZ0r0Jjw9Nty4ySksVFo6DT/9i4zYkoOISxB3AZUBjoK/XYA0gFfjfSAcWl1LTYdP8kpczvgts2/DUJd248ISm1uittA7ugcl/hqXvWduGBFVcZ30KTAgyfUFEI4pnKemwbBIc3AtVavkdjQmicNuGZy8/ntYNa/gdVvzJmAvvXQd7MqxtQwKzEeXCKdWrqN66DFr09jcWc5TAtg3X923FXwZ2oHKy/aiVSn4+zHgGpj4BNZvYuA0JzhJEOB3ucmOpJYgYEti2oXqlZF699iROt9tXS2/fFph4g7VtKEcsQYRTrSZQta67k8PEhD0Hcrh34mI+W7qFfu0a8NSl3WhU0+6uKbVVX8AHwyH7gI3bUI6EMib1Eo7upnsPrvO8x1V1RyQCi0si7irC7mSKCda2IQxyD8FXD8Osf7vP9sWvWNuGciSUK4jPgDzgLe/15d7fvbghQM8Lf1hxLLULzH0V8vOs0s4n1rYhTALbNpx8I5z1qLVtKGdCSRB9VLVPwOslIjJDVfuIiA2hVlhKOuRmwc410KCd39GUO9a2IQysbYPxhJIgaohIT1WdDSAiJ+PGj4bfxo82BVK9iuotSyxBRNkXy7Zwt7VtODY5WfDhrda2wQChJYjrceNS18B1v7EXuF5EqgN/i2RwcalBB5AkVw+RfqHf0ZQLB3Py+L9PV/D6D9a24Zj9OMYlh9MfgH5/tmLScq7EBKGqc4AuIlIbN37E7oDZ70QssnhVsQo0aG+DB0XJz1v3cdv4Bfy0xdo2HLPcbJj1PLQ6DU77i9/RmBgQyl1MlYGLgJZAcsElu6o+GtHI4llqOqyf6XcUCc3aNkTAkndh3y8wZJTfkZgYEUoR04e421rnEdpY1CYl3X3ZDuyEavX8jibh7DmQw32TFvPpEmvbEDb5+TDzOffZbXOm39GYGBFKgkhT1YERjySRFFRUb10Grfr5G0uCmbtuJyMmLGTr3oPcO6gjN1jbhvBY/SVkroALxlgDOHNYKGNjzhSRLhGPJJEUDB5kDebCJi9fefbrn7n0xR9IqiC8d9MpDD+tjSWHcJnxLNRKsxsrzBFCuYLoC1wjImtxRUyC6+y1a0Qji2c1U6B6Q6uoDpNf9mRxx4SFzF67k/O7NeGJC6xtQ1hlzIP138PZT0CSva/mN6EkCGshUxYp6bDV+mQ6VoFtG/55STcusrYN4TdzJFSuDSf+3u9ITIwpMkGISC1V3Qvsi2I8iSM1HWaPgbxcSLI+EUsrsG1D5ya1eG6YtW2IiJ1rYMXH0GcEVK7pdzQmxhT3y/UWMBh395Jy5BjVCrSOYFzxL6UL5B2CHT+78apNyKxtQxT9MBoqJLtxpI0ppLgR5QZ7f1tFL5wEcrjLjaWWIEJ0VNuGa07i9I7WtiFi9m+HBW9C18ugZqrf0ZgYVOJdTCLydSjTTCEN2kNSJauHCNGeAznc8tZ87p+0hB4t6vHZiH6WHCLtx5cg9yCccpvfkZgYVVwdRBWgGtBAROryWxFTLcB67ypJUkXXb77dyVQia9vgg+wDrt+l9oNsfAdTpOLqIG4E7sAlg3n8liD2AqMjHFdiSEmH/37jdxQxKy9fGT11Nc98ZeM2RN3CcZC1E/rc7nckJoYVVwcxEhgpIrep6nNRjClxpKTDovHwaybUaOh3NDHF2jb4KD8PfhgFaSdBcxs73RQtlJbUW0SkJoCIPCAiE0XkhAjHlRgOd7lh9RCBvli2hUEjp7Nk0x7+eUk3Rl7e3ZJDNK34CHatg1Nut241TLFCSRB/VdV9ItIXOAd4DXg+soL9tyoAACAASURBVGEliMNdbizzN44YcTAnjwc/XMoNb8yjaZ2qTL6tLxefmGYN36JJFWaMhHqtoePv/I7GxLhQEkSe9/d3wPOq+iFQKZSNi8hAEVkpIqtF5N4g82uLyMciskhElonItQHz6ojIeyLyk4isEJH4uxauXh9qNraKalzbhqGjZ/D6D+u5vm8rJt58ijV888O672HzAnfnkg0GZEoQShPfTSLyIjAA+Ls3PkQot8cm4SqzzwIygDki8pGqLg9Y7BZguaqeJyINgZUiMk5Vs4GRwOeqerGIVMLdURV/UtLLdad9qsqEORt55GNr2xATZj4L1RpAt2F+R2LiQChXEJcCU4CB3mhy9YBQhps6GVitqmu8H/wJwJBCyyhQU1wZQw1gJ5ArIrWAU4H/AKhqdqGR7MLmYE4ed727iA8XborE5l09ROZKN1pXOaKqzFu/kz++Po/7JlrbhpiwdTn8/AX0vBEqVvU7GhMHQhly9ICIbMP16vozkOv9LUlTYGPA6wygZ6FlRgEfAZuBmsBlqpovIq2BTOBVEemGu812hKruL7wTEbkBuAGgefPmIYR1pMrJFZi1Zgd7s3IY0r1pqdcvUUo65OfA9pWQmvi9pu89mMMHCzYxbtYGVm7dR43Kyda2IVbMfA4qVoOTrvc7EhMnQhly9CGgB9ABeBWoCLwJ9Clp1SDTtNDrc4CFwBlAG+BLEZnuxXUCcJuqzhaRkcC9wF+P2qDqGGAMQI8ePQpvv0QiQr92Dfl40WZy8vKpmBTKRVUpFCSFLUsTNkGoKosz9vDW7A18tGgzWTl5dGlamycv7MJ53ZpQvbJ1Vui7vZvdKIc9rrNRDk3IQvnmXgAcD8wHUNXNBbe9liADaBbwOg13pRDoWuBJVVVgtTfmREdgA5ChqrO95d7DJYiIOK19A8b/uIGFG3dzUsswf3nqtYHkKglZD/HroVw+WriZcbPXs2zzXqpWTGJI9yZc0bM5XdOswVtMmfU8aB70vtnvSEwcCSVBZKuqiogCiEj1ELc9B2gnIq2ATcDlwBWFltkAnAlMF5EU3FXKGlXdLiIbRaSDqq70lllOhPRu04AKAt+tygx/gkhKdp31bUmcthDLNrurhQ8WbGJ/dh4dU2vy2JDODDm+KbWsPUPsObgH5r4KnS+Aui39jsbEkeL6Yvo/Vb0feMe7i6mOiPwRuA54qaQNq2quiNyKq+BOAl5R1WUiMtyb/wLwGDBWRJbgiqTuUdXt3iZuA8Z5dzCtwV1tRETtqhXp3qwO3/28nTvPjkC/NCnpsPJTdw96nN7zn5Wdx8eLN/PWbHelVTm5AoO7uquFE5rXsbYMsWzeWMje5xrGGVMKxV1BDATuV9V/ishZuD6YOgAPquqXoWxcVT8FPi007YWA55uBs4tYdyGu7iMqTm3fkJFf/8zuA9nUqRZSM4/QpXaBBW/Avi1Qq3F4tx1hq7bu463ZG3h/fgb7DubStlENHhzciYtOSKN2NbtaiHm52a54qdWp0KS739GYOFNcgkgK6MV1nvcAQETqqerOSAcXTf3aNeSZr37m+9XbGdw1zJ3VphR0ubE0LhLEwZw8Pl+6hXGz1zNn3S4qJVVgYHoqV/Zszsmt6tnVQjxZ8i7s+wWGjPI7EhOHiksQHfmtF9fAu4MKXifUiHLd0mpTs0oy01dFIkF0cn+3LIF2Z4V322G0JvPXw1cLuw7k0LJ+Ne4b1JGLT0yjfo3KfodnSkvV3dqakg5tzvQ7GhOHiksQy1X1+KhF4rPkpAr0bduA737ORFXDe5ZctS7UbhaTdzJl5+bzxfItjJu1gR/W7CC5gnB25xSu7NmC3q3rW9uFePbzl5C5Ai54MW7rvoy/7Ab1AP3aNeSzpVv4b+avtG0U5gHcU9JjqtO+DTsOMH7OBt6du5Htv2aTVrcqfzmnA5f0SKNRzSp+h2fCYcZIqJUG6Rf5HYmJU8UliJFRiyJG9GvXAIDvVm0Pf4JITXfdHOQchIr+/ADn5uXz1YptvPXjBr5blUkFgTOPS+GKns05tV1DkuxqIXFsmgfrv4ezn3CjGxpTBsUNGDQ2inHEhGb1qtG6QXW++zmT6/q2Cu/GU9JdQ6XMFdAkuiV3m3Zn8faPG3h77ka27j1Eaq0q3DGgHZed1IzGta1PnoQ041moXBtO/L3fkZg4ZkVMhfRr14C3527kUG4elZPD2B1yYJcbUUgQefnKtJXbeGv2Bqau3IYCp7VvyONDW3B6h4Ykh7tLERM7dq5xgwKdcjtUDvOVsClXik0QXpfdt6vqv6IUj+9Obd+Q135Yz9x1u+jTtkH4Nly3FVSsHvGK6q17D/LOnI1MmLORTbuzaFCjMjf3b8tlJzWjWb347DHdlNIPo6FCMvQc7nckJs4VmyBUNU9EhgDlJkH0al2fiknCdz9nhjdBVKjgbneNwOBB+fnK96u3M272er5asY28fKVv2wY88LvjGNApJfwdEJrYtX87LBgHXS+NizY3JraFUsQ0Q0RGAW8Dh7vbVtX5EYvKR9UrJ3NC87pMX7Wd+waFeeMp6bBsYti63Nj+6yHenZvB+B83sGHnAepVr8T1fVsx7OTmtGwQapdZJqH8+BLkZlm3GiYsQkkQp3h/Hw2YprguuhPSqe0b8o8pK8ncd4iGNcPYQCw1Hea9CnsyoE6zkpcPQlX5Yc0O3pq9gSnLtpCTp/RsVY87z27PwPTU8NabmPiSfQB+HAPtB0HDCPQpZsqdUAYMOj0agcSSU9u5BPH96kwuOD4tfBtO8Sqqty4tdYLYtT+b9+dn8NbsDazZvp9aVZK5uldLrujZLPy35Jr4tHAcZO2EPnb1YMIjlAGDagMP4YYABfgWeFRV90QyMD91blKLetUr8d2q7WFOEAVdbiyFDiWXX6kqc9fv4q3ZG/hkyS9k5+ZzYou6PHV6W37XtTFVKtrVgvHk58EPo6BpD2je2+9oTIIIpYjpFWApbmxqgKtxI8tdGKmg/FahgtC3bQM+XrSZ71dvL3mFUphIKiunfc1935d8q2tuXj67DuRQs3Iyl5/UjCt6Nqdjaq2wxhNRB3bCO/8D3a+E7sP8jiaxrfgIdq2Dsx6zbjVM2ISSINqoamBb/UdEZGGkAooVN/VvQ80qyeSXehDT4u1Z157uB9cwoGNKSMt3b1ab87o1oVqlOGuykpfjksO66ZAxF9J6QIN2fkeVmFRdw7h6raHj7/yOxiSQUH51skSkr6p+DyAifYCsyIblv+Ma1+KJCyIwhvS0PjBtOn8b3BoqJfCdRp/f65LDWY/C9/+CSTfCdV+4EfZMeK2fAZvnw++ehgpW7GjCJ5Qb5IcDo0VknYisA0YBN0Y0qkSWkg4obFvhdySRM+dl9zjldugzwv1wbZrnEoUJvxkjoVoD6F54RF9jjk2RCUJERnhPa6hqN6Ar0FVVj1fVxVGJLhGleoMHJdAY1UdY+x18eje0OwcGPOympV8I6RfDt0/C5oQvnYyubStcJ5A9b4SK1q+WCa/iriAKxoB+DkBV96rq3siHlODqtIDKtWJybIhjtnONq3eo3xYuevnI4o5z/wHVG7qippyD/sWYaGY+BxWrwUnX+x2JSUDFJYgVXpFSBxFZHPBYIiJ2BVFWIpDSOSJdbvjq4F4Y792pNGw8VCl0t1W1em7Yy8yf4JvHoh9fItq7GRa/A8df7d5fY8KsuO6+h4lIKjAFOD96IZUDKemwaALk57s+muJdfh5M/CNs/xmungT12wRfru0A6PEH15lch0HQsm9040w0s553Xcj3vtnvSEyCKvbXSVW3qGo3VV1f+BGtABNSajpk74PdCfI2fv0orPocBv0dWp9W/LJnPwZ1W8IHN7mrDlM2B/fAvLHQaah7P42JgAQ4fY1DgV1uxLtFE2DGM9DjOjj5jyUvX6m6GyN5TwZMuT/y8SWqeWPh0F7rVsNElCUIPzQ6DqRC/NdDZMyFj26Hlv1g0P8Lfb3mPaHPHbDgDVj5WeTiS1S52TDrBWh1atRHJzTliyUIP1SqBvXaxPcVxJ5NMOEKqJkKl7xW+nGP+9/nrqQ+us2NYWBCt/Q92LcZThlR8rLGHIPi2kEkiciNIvKY13o6cN4DkQ8twaWmx29biOwDLjlk74cr3obq9Uu/jeRKcMELrix98h2uuwhTsoJuNRp1hrZn+h2NSXDFXUG8CJwG7ACeFZGnA+YlbEd9UZOS7iqp462iVhU+uhV+WQQX/ccVl5VVajqc/r+w4mN3u6Yp2c9fQuYKV/dgnfKZCCsuQZysqleo6jNAT6CGiEwUkcqAfTKPVWpBRfUyf+Moren/hKXvw4CHoMPAY9/eKbdBs17w6V9cxbUp3sxnoVZTSL+o5GWNOUbFJYhKBU9UNVdVbwAWAt8ANSIdWMJL6ez+xlM9xIqP4ZvHoetlrpI5HCokwQXPQ34ufHCzaxtigts0z3WA2Oum0tf5GFMGxSWIuSJyxCmiqj6KGwuiZSSDKhdqNYUqdeInQWxZChNvhKYnwnnPhrd4o15rOOcJWPut6+TPBDfjWahcG074vd+RmHKiyAShqlep6udBpr+sqiGdvojIQBFZKSKrReTeIPNri8jHIrJIRJaJyLWF5ieJyAIRmRzK/uKKiCtmiodbXX/NdN1oVKkFl78FFauEfx8nXgNtz4IvH3Qtss2Rdq51gwL1uPbobkyMiZASb3MVkTJ1MO+tNxoYBHQCholIp0KL3QIs93qL7Q88JSKVAuaPABK3X+yUdNi23HVVEatys10HfPu3ueRQMzUy+xFxfTVVrOI69MvLjcx+4tUPo0GSoOdwvyMx5UixCUJEagIflnHbJwOrVXWNqmYDE4AhhZZRoKaICK5eYyeQ6+07DfgdkLhlDqnpkHPAnR3GIlX49E7YMBOG/huanhDZ/dVMtbEjgtm/Axa8Cd0ug1qN/Y7GlCPFtYNoDHwFjCnjtpsCGwNeZ3jTAo0CjgM2A0uAEapaUEv5DHA3kLi1line2BBbY7Q9xOwXYf7r0O+u6N01Y2NHHG3OS5Cb5QZgMiaKiruCmA48qaoflXHbwWoxC7eGOgd3Z1QToDswSkRqichgYJuqzitxJyI3iMhcEZmbmZlZxlB90rCjKzaIxXqI1V/DlPug42DXViGabOyI32QfgB/HQPuB0LCD39GYcqa4BLGLo8/4SyMDaBbwOg13pRDoWmCiOquBtUBHoA9wvjcexQTgDBF5M9hOVHWMqvZQ1R4NGzY8hnB9ULEKNGgfe3cybV8N710LDY9zHetFu0tyGzviNwvHwYEdbuhWY6KsuG9+f2CQiNxSxm3PAdqJSCuv4vlyoPDVyAbgTAARSQE6AGtU9T5VTVPVlt5636jqVWWMI7alpsfWFUTWbhh/GVRIdgP/VPapyUvg2BHrvvcnBr/l57njb9oDmvf2OxpTDhV3m+t+3EBBZeouUlVzgVtxAw6tAN5R1WUiMlxECm7FeAw4RUSWAF8D96hq+eq5LSUd9mbAgZ1+R+LuHHrvOti1Hi59A+q28DeewLEjDu3zNxY/rPgYdq21bjWMb4ocUQ5AVfOAMg92q6qfAp8WmvZCwPPNwNklbGMaMK2sMcS81IKK6mXQqp+/sXz5IPz3a9cQrmWfkpePtIKxI14d6MaOOP85vyOKHlWYMdI1Iuw42O9oTDlV6sJlr/HalZEIplyKlcGD5r8Bs0a7++xPjKGWugVjR8x/HVYe1W4zca2fAZvnQ+9bXXckxviguNtca4nIfSIySkTOFuc2YA1wafRCTHA1U9wdO37WQ6z/ASb/CVqfDmc/4V8cRTli7IgdfkcTHTOehWoNoPsVfkdiyrHiriDewFUaL8EVM30BXAwMUdXCDd7MsUjp7F9biN0b4O2roE5zuORVSCq21NEfh8eO2F0+xo7YtgJ+ngIn3wAVq/odjSnHiksQrVX1GlV9ERgG9AAGq6q1Xgq3lHTY9lP0u5c49CuMvwLycmDYBKhaN7r7L43DY0d8BEve9TuayJr5HFSsFtoY38ZEUHEJIqfgiVdZvVZVy+GtJFGQ2gXyDsGO1dHbZ34+fDActi2Di1+Bhu2jt++yKhg74pO73JCniWjvZjd40vFXufYgxviouATRTUT2eo99QNeC5yISZ8OgxbjDXW5EsR7i2yfdbZRnPw7tBkRvv8cicOyIDxN07IhZz4PmQe+yNj8yJnyKaweRpKq1vEdNVU0OeG79DYdTg/ZQoWL0xqheOhG+/Tt0vwp63RydfYZLvdZwzuOwZhrM/Y/f0YTXwb0wbyx0Gurafxjjsyj3oWCCSq7k+mWKxhXE5oVu5LZmPWHw0/HZAOvEa11L6y/+6roFSRTzxsKhva5hnDExwBJErIhGlxv7tsKEK6BafbjsTUiuHNn9RYoInD/KxZ8oY0fkZrvipZb9oEmZOi8wJuwsQcSKlHT4dQvsj1BPIzkH4e0rIWuX62OpRqPI7CdaajV2V0Cb5sKMBBg7Yul7sG9z+Mb6NiYMLEHEioIuNyJRD6Hq2g9kzHHtCRp3Df8+/JB+kXtMexJ+WeR3NGWn6m5tbdQZ2p7pdzTGHGYJIlZEssuNmc/BovHQ/37olGBtHM/9p2txPDGOx45Y/ZUbevaU2+KzTsgkLEsQsaJ6fajZOPz1EKu+cJ3wdRoKp90d3m3Hgmr1YMhoyFwBUx/3O5qymTESajWN3qh9xoTIEkQsSUkP7xXEtp9c992pXWDo84l7dtpuAPS4DmaOgnUz/I6mdDbNh3XToddN7m42Y2KIJYhYkpoOmSvdHS3H6sBOGH+568tn2HioVO3YtxnLzioYO2J4fI0dMfNZqFwLToihHnSN8ViCiCUp6ZCfA9tXHtt28nLg3d/D3k1w+TionRae+GJZ5RquAn5Phhs7Ih7sXAvLP3RXP1Ws7amJPZYgYklKwOBBx+Lz+2Dtd3DeSGh28rHHFS+a93JjN8fL2BE/jAZJcmNwGBODLEHEkvptIanysd3qOvcVmPOSuyOmPI4l0P8+l2hjfeyI/TtgwZvQ9TLXpsOYGGQJIpYkJUOj48peUb12Onz6F2h3Ngx4JLyxxYvkym6Y0qxdsT12xJyXIDfLJXJjYpQliFhT0OVGaX/Ydq6Fd66Gem3gopfL9zCVqelwRgyPHZF9AH4cA+0HQqOOfkdjTJEsQcSalC5wYDv8ujX0dQ7uhfHDXFIZNh6q1I5cfPHilNtdh4SxOHbEorfgwA4XozExzBJErDnc5UaIxUz5eTDxBti+Ci59Deq3iVxs8aRCkrurKdbGjsjPc+01mp4ILU7xOxpjimUJItakdHZ/Qx2j+pvHYNVnMOjv0Lp/pKKKT7E4dsSKj2HXWne3VaI2XDQJwxJErKlaF2o3C+0KYvE78P2/3PgIJ10f+djiUSyNHaHqGsbVaw0dB/sbizEhsAQRi0LpciNjHnx4K7ToC+f+w85GixJLY0esnwmb5rnhRMvzTQQmbliCiEWp6bD956J7J9272Q38UzMVLn0dkipGN754EytjR8wY6Xqe7X6lfzEYUwqWIGJRSrobuD5zxdHzcrJccsj+FYZNcL3AmpL5PXbEtp/g5ylw8g2ufyxj4oAliFiU6o0NUbgeQhU+vMWNK33hS5DSKfqxxTM/x46Y+RwkV7W6IhNXLEHEorqtoGK1o+shpj8FS9+HMx+Ejuf6E1s8O2LsiCeit9+9m2Hx23DC1XbFZ+KKJYhYVKECNOp0ZKd9P33ibmntcin0/ZN/scW7w2NHPOcqjaNh9guuyLD3LdHZnzFhYgkiVqWmu077VF1R0/t/hCYnwPnP2h1Lx6pg7IhJURg74uBemPuqG+q1bsvI7suYMItoghCRgSKyUkRWi8i9QebXFpGPRWSRiCwTkWu96c1EZKqIrPCmj4hknDEpJR0O7nYVquOHufECLn/LKjjD4fDYERthyv9Gdl/zxsKhvdatholLEUsQIpIEjAYGAZ2AYSJSuFb1FmC5qnYD+gNPiUglIBe4U1WPA3oBtwRZN7EVVFSPuxj2b3MD/1i30OFzeOyI12DVlMjsIzcbZj0PLftB0xMisw9jIiiSVxAnA6tVdY2qZgMTgCGFllGgpogIUAPYCeSq6i+qOh9AVfcBK4CmEYw19hR0ubE/01WsNj3R33gSUcHYER/eGpmxI5a+D/s2u0RkTByKZIJoCmwMeJ3B0T/yo4DjgM3AEmCEqh7Rq5qItASOB2YH24mI3CAic0VkbmZmZngijwWVa0Knoe6OpS4X+x1NYgocO+KTP4V37IiCbjUadXJdfRgThyKZIILVpBb+Bp4DLASaAN2BUSJyeHBeEakBvA/coap7g+1EVceoag9V7dGwYcPwRB4rLn0N+t3pdxSJrWDsiOUfwpL3wrfd1V/BtuWu7sFuKjBxKpIJIgNoFvA6DXelEOhaYKI6q4G1QEcAEamISw7jVHViBOM05V3B2BGf3hm+sSNmjISaTVzrbWPiVCQTxBygnYi08iqeLwc+KrTMBuBMABFJAToAa7w6if8AK1T16QjGaMxvY0fk5bqW6sda1LRpPqybDr1uguRK4YnRGB9ELEGoai5wKzAFV8n8jqouE5HhIjLcW+wx4BQRWQJ8DdyjqtuBPsDVwBkistB7WNNhEzmHx46YCnNePrZtzXwWKteCE68JS2jG+CU5khtX1U+BTwtNeyHg+Wbg7CDrfU/wOgxjIufEa12L9S/+Cm3OKNvofDvXuvqMU25zbVeMiWPWktqYAuEYO+KH0SBJ0POm8MdnTJRZgjAmUMHYERlzYMYzpVt3/w5Y8CZ0vcwaNZqEYAnCmMIOjx3xt9KNHTHnZcjNcsVLxiQASxDGBFMwdsSk4aGNHZGTBT++CO3OgUYdIx+fMVFgCcKYYArGjti2PLSxIxaOgwM7rFsNk1AsQRhTlFDHjsjPg5mjXH9ZLU6JXnzGRJglCGOKE8rYET9Nhl1rrVsNk3AsQRhTnJLGjlB13WrUbQXHnRf9+IyJIEsQxpSkuLEj1s+ETfPglFtdlx3GJBBLEMaEoqixI2Y+C9XqQ/cr/YvNmAixBGFMKIKNHbHtJ1j1OZx8ow0FaxKSJQhjQlV47IiZz0FyVTjper8jMyYiItpZnzEJ55TbYeVn8MmdkHPA9dhavb7fURkTEXYFYUxpFIwdkZ8Lmge9b/E7ImMixq4gjCmteq3hstdhTwbUa+V3NMZEjCUIY8qi7QC/IzAm4qyIyRhjTFCWIIwxxgRlCcIYY0xQliCMMcYEZQnCGGNMUJYgjDHGBGUJwhhjTFCWIIwxxgQlqup3DGEjIpnA+ijsqgGwPQr7iTY7rviTqMdmxxU9LVS1YbAZCZUgokVE5qpqD7/jCDc7rviTqMdmxxUbrIjJGGNMUJYgjDHGBGUJomzG+B1AhNhxxZ9EPTY7rhhgdRDGGGOCsisIY4wxQVmCMMYYE5QliGKIyCsisk1ElgZMqyciX4rIz97fun7GWBYi0kxEporIChFZJiIjvOmJcGxVRORHEVnkHdsj3vS4PzYAEUkSkQUiMtl7nSjHtU5ElojIQhGZ602L+2MTkToi8p6I/OR933rH03FZgijeWGBgoWn3Al+rajvga+91vMkF7lTV44BewC0i0onEOLZDwBmq2g3oDgwUkV4kxrEBjABWBLxOlOMCOF1Vuwe0E0iEYxsJfK6qHYFuuP9d/ByXqtqjmAfQElga8Hol0Nh73hhY6XeMYTjGD4GzEu3YgGrAfKBnIhwbkIb7QTkDmOxNi/vj8mJfBzQoNC2ujw2oBazFuxkoHo/LriBKL0VVfwHw/jbyOZ5jIiItgeOB2STIsXnFMAuBbcCXqpoox/YMcDeQHzAtEY4LQIEvRGSeiNzgTYv3Y2sNZAKvesWCL4tIdeLouCxBlGMiUgN4H7hDVff6HU+4qGqeqnbHnXGfLCLpfsd0rERkMLBNVef5HUuE9FHVE4BBuCLPU/0OKAySgROA51X1eGA/sVycFIQliNLbKiKNAby/23yOp0xEpCIuOYxT1Yne5IQ4tgKquhuYhqtHivdj6wOcLyLrgAnAGSLyJvF/XACo6mbv7zZgEnAy8X9sGUCGdwUL8B4uYcTNcVmCKL2PgN97z3+PK7+PKyIiwH+AFar6dMCsRDi2hiJSx3teFRgA/EScH5uq3qeqaaraErgc+EZVryLOjwtARKqLSM2C58DZwFLi/NhUdQuwUUQ6eJPOBJYTR8dlLamLISLjgf64Lnq3Ag8BHwDvAM2BDcAlqrrTrxjLQkT6AtOBJfxWnn0/rh4i3o+tK/AakIQ7AXpHVR8VkfrE+bEVEJH+wF2qOjgRjktEWuOuGsAVy7ylqk8kyLF1B14GKgFrgGvxPpfEwXFZgjDGGBOUFTEZY4wJyhKEMcaYoCxBGGOMCcoShDHGmKAsQRhjjAnKEoSJCyKiIvJUwOu7ROThMG17rIhcHI5tlbCfS7wePacWmt5SRLK8nkwLHpXKsP1rRKRJ+CI25Z0lCBMvDgEXikgDvwMJJCJJpVj8D8DNqnp6kHn/VdeTacEjuwzhXAOUKkGISHIZ9mPKCUsQJl7k4sbz/VPhGYWvAETkV+9vfxH5VkTeEZFVIvKkiFzpjRexRETaBGxmgIhM95Yb7K2fJCL/EJE5IrJYRG4M2O5UEXkL19iwcDzDvO0vFZG/e9MeBPoCL4jIP0I5YBE5W0R+EJH5IvKu13cWIvKgF9NSERkjzsVAD2CcdwVSVdwYCw28dXqIyDTv+cPeel8Ar3utz9/3tjlHRPp4y50WcEWzoKC1sylH/O5O1h72COUB/IrrPnkdUBu4C3jYmzcWuDhwWe9vf2A3rkvlysAm4BFv3gjgmYD1P8edMLXD9aFTBbgBeMBbpjIwF2jlbXc/0CpInE1wrWMb4loFfwMM9eZNA3oEWaclkAUs9B6jca33vwOqe8vcAzzoPa8XsO4bwHnBtk9AF9q45DHNe/4wYPfMgAAAAlJJREFUMA+o6r1+C+jrPW+O64IF4GNcJ3oANYBkvz8H9ojuwy4vTdxQ1b0i8jpwO+4HNRRz1OtaWUT+C3zhTV8CBBb1vKOq+cDPIrIG6IjrE6hrwNVJbVwCyQZ+VNW1QfZ3Eu6HONPb5zjgVFwXLcX5r7oeaPHWGwx0Ama4rrOoBPzgzT5dRO7GjXdRD1iG+zEvjY9UteA9HAB08vYDUMu7WpgBPO0dw0RVzSjlPkycswRh4s0zuEGAXg2YlotXXOp1RBhYwXso4Hl+wOt8jvz8F+5zRgEBblPVKYEzvL6Q9hcRnxQxvbQEN5bFsEL7rgL8G3elsNGrqK9SxDYOvy9BlgmMvwLQOyBhFHhSRD4BzgVmicgAVf2p9Idi4pXVQZi4oq5Ts3dwFb4F1gEnes+HABXLsOlLRKSCVy/RGjfq1xTgJnFdoyMi7b3eRoszGzhNRBp4FdjDgG/LEM8soI+ItPX2XU1E2vPbD/12r04i8O6rfUBgPcE6fntfLipmX18Atxa88DqYQ0TaqOoSVf07rnitYxmOw8QxSxAmHj2FK6Mv8BLuR/lH3PCiRZ3dF2cl7of8M2C4qh7E9cK5HJgvIkuBFynhqtsrzroPmAosAuaraqm7c/aKqK4BxovIYlzC6KhujIuXcEVkHwBzAlYbi6sEXyiuq/NHgJEiMh3IK2Z3twM9vIr45cBwb/odXkX4IlyR3melPQ4T36w3V2OMMUHZFYQxxpigLEEYY4wJyhKEMcaYoCxBGGOMCcoShDHGmKAsQRhjjAnKEoQxxpig/j86w+dVp+I11QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = data.Features\n",
    "MLR = data['MLR_R^2']\n",
    "DL = data['DL_R^2']\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,MLR, label='MLR')\n",
    "ax.plot(x,DL, label='DL')\n",
    "ax.set_title(\"Multiple Linear Regression VS Deep Learning\")\n",
    "ax.set_xlabel(\"Number of Features\")\n",
    "ax.set_ylabel(\"R^2 for Testing Set \")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other\n",
    "# X_scaler.scale_\n",
    "# X_scaler.inverse_transform\n",
    "# y_test_pred = np.exp(y_test_pred)\n",
    "# X_scaler.inverse_transform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
